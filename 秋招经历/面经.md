## 一. **刷题**

### 面试问过的

+ 给定一个数组num和两个数字L和R，数组长度为n，问你这个数组里面有多少个连续的子数组，满足这个子数组中的最大值大于等于L，小于等于R。
+ 给一个字符串，输出最长连续子串。
+ n的所有最小因数集合，如8，其最小质数集合为{1,2,2,2}
+ 手撕 unique_pointer
+ [个人博客 - 设计parser](https://xyfu.me/posts/de9ec62b/)
+ 布隆过滤器
+ hash表解决冲突的方法
+ 红黑树性质
+ redis中的数据结构
+ 跳表插入删除过程
+ 判断大小端，int的大端转小端
+ 去掉字符串开头和末尾的空格
+ 大数相加
+ 最长公共子序列LCS
+ 最小编辑距离
+ 二叉树中两个节点的最近公共父节点
+ 数据流的中位数
+ [算法题](https://www.nowcoder.com/jump/super-jump/word?word=算法题)是两个[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)数组，找中位数。我回答了lc上的O(log M +N )的最优解方法
+  40E个数，找出唯一不存在的数？进行(内存)优化？大数据问题都是用[哈希表](https://www.nowcoder.com/jump/super-jump/word?word=哈希表)进行分组，每一组做一次遍历，就可以大大减少内存占用
+ 1~N，其中有两个数重复，找出重复的数？
+ 写个单例模式的例子
+ 设计题，快速找出所有微信关系里的单向好友
+ 一个字符串ajxnhdbdosjbsorange,模式“o*ge”,找到匹配的最小字符串下标范围。
+ hashfunc一般怎么实现(除法散列，乘法散列 等等)
+ hashmap发生冲突怎么解决([链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)法、开放寻址法等等)
+ 1亿个数怎么找中位数(哈希分组，然后快排寻找)
+ 一个字符串，比如abc123/f/ecd,连续的数字或者连续的字母，或者反斜杠后和后面一个字符，视为一个整体，反转之。比如这时输出应该是cd/e/f123abc.(一开始用了栈来做，非常简单。然后面试官问有没有其他方法，我就说一个先分段反转再整体反转的原地做法。
+ 开放寻址法要如何查找一个元素
+ 一个无序数组,如何寻找第n大的数(BFPTR[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法))
+ 单向[链表]()中如何高效删除一个结点（只给定头指针和指向当前结点的指针）  
+ 给定n个正整数，如何找出最小的K个正整数 
+ 给定一组整数1000以内，如何高效去除重复的数
+ 字符串中查找是否有子串，写完以后要求给出测试用例

### 链表

+  **从尾到头打印链表**
  + 反转链表；打印后反转；使用栈
+  **链表中倒数最后k个结点**
  + 双指针：一个先行，一个后行
+   **反转链表**
  +  双指针： 不停反转，直到链尾
+  **合并两个有序链表**
  + 双指针：
+  **复杂链表的复制**
  + 双指针
+   **两个链表的第一个公共结点**
  +  双指针：设置 p1,p2分别指向各自链表进行前行，遇到链尾时指向对方链头，知道双方结点相同。
+   **链表中环的入口结点**
  + 双指针：设置快慢指针fast,slow，相遇表示有环；设置指针p指向head，p与slow相遇，则是入环结点。

+   **删除链表中重复的结点**
  +  双指针：



##  二 .C++

+ 在一台内存为2G的机器上，malloc(20G)会怎么样？new 20G呢？
+ 虚函数的作用及实现原理
+ 局部变量、全局变量、常量还有malloc开辟的内存变量分别放在哪个区
+ 全局变量的初始化位置
+ 游戏中，有些资源文件需要频繁使用，如何进行加速  
+ 游戏中，如果有一个AOE的BUFF（类似皇子的旗子E技能），如何实时快速计算这些技能的影响单位 

---

### C相关问题

+  **C程序如何启动和终止的**
  + 内核调用一个exec函数，调用exec的进程将命令行参数传递给启动例程，然后启动例程调用main函数。
  + 进程自愿终止的唯一方法是显式或隐式地(通过调用exit)调用\_exit或 \_Exit。进程也可非自愿地由一个信号使其终止。

+  **atexit函数**
  + atexit函数类似于C++类中的析构函数，在main函数结束之后被exit调用，调用顺序与登记顺序相反。同一函数如若登记多次也会被调用多次。
  + `atexit`的参数是一个函数地址，无需传递参数,也不期望返回值。

+  **C程序的存储地址空间布局**
  + 从低地址往高地址分别为： 正文段—> 初始化数据段—> 未初始化数据段—> 堆——>栈。
  + 它们的主要作用：
    + 正文段：这部分是共享的，也是只读的，是CPU执行的机器指令部分。
    + 初始化数据段：包含程序中需明确地赋初值的变量
    + 未初始化数据段：也称为bss段( block started by symbol)，在程序执行之前，内核将该段中的数据初始化为0或空指针。
    + 堆：动态分配存储的区域
    + 栈：自动变量以及函数调用所需要保存信息的区域

+  **什么是共享库，有什么优点**
  + 库是一种可执行代码的二进制形式，可以被操作系统载入内存执行。共享库可以让它的代码同时为多个进程所用，而代码实例在整个内存空间中仅需一份。
  + 优点：
    + 程序调用动态库函数时，用动态链接方法将程序与共享库函数相链接。缩少了可执行文件的大小。
    + 新版本代替老版本时，无需对使用该库的程序重新连接编译。
+  **讲一下存储空间分配函数——malloc, realloc, calloc各自的用法**
  + `void *malloc(size_t size);`  分配指定字节数的存储区，初始值不确定
  + `void *calloc(size_t nobj, size_t size);` 分配指定 数目，长度 的存储空间， 初始化为0
  + `void *realloc(void *ptr, size_t newsize);` 增加或减少以前分配区的长度，新增区初始值不确定
+   **C++ 中的 string 与 C 中的 `char *` 有什么区别？**
  + string继承自 basic_string ，是对 `char` 进行了封装，包含 char 数组，容量，长度等属性
  + string可以动态扩展，每次扩展是原空间的两倍，将原内容拷贝进去。

### C++基本介绍

---

+  struct和union的区别
+ 介绍auto,主要是会覆盖顶层的引用和修饰。
+ 如果要保留顶层的引用和修饰要用什么？decltype
+  什么是字节对齐
+ 知道虚函数表指针在内存中是怎么分布的吗？(我直接按照Lippman那本书回答)。
+ 虚函数表指针放在头部和尾部的好处分别是什么？(自己挖的坑。。)

---

+ 聊一聊C++面向对象的三大特性

  > C++ 的三大特性就是继承，封装和多态。

  + 继承：让某种类型对象获得另一个类型对象的属性和方法。有三种继承方式：
    + 实现继承：指使用基类的属性和方法而无需额外编码的能力
    + 接口继承：指仅使用属性和方法的名称、但是子类必须提供实现的能力
    + 可视继承：(C++里好像不怎么用)
  + 封装：变量和方法捆绑成类，可以对它们进行信息隐藏，只让可信的对象和类操作。
  + 多态：同一事物表现出不同事物的能力。实现多态的两种方式：
    + 覆盖： 是指子类重新定义父类的虚函数的做法。
    + 重载：是指允许存在多个同名函数，而函数的参数表不同

### 变量与基本类型

---

+  **变量与定义的区别**
  + 声明仅仅将变量声明的位置与类型提供给编译器，并不分配内存。定义会在定义的地方直接分配存储空间。
  + 相同变量可在多处声明，但只能一处定义。
+  **什么情况下必须用到初始化成员列表**
  + 初始化const成员
  + 初始化reference成员
  + 调用基类的构造函数，该函数有参数
  + 调用数据成员对象的构造函数，该函数有参数
+  **常量指针与指针常量的区别**
  + 常量指针指常量的指针，注重常量，不能修改指定的值 ：`int const *p` 或 `const int *p`
  + 指针常量指不能修改指针的指向，指针是一个常量： `int *const p` 。
+  **介绍野指针与空悬指针，如何避免？**
  + 野指针：没有初始化的指针
  + 空悬指针： 指针最初指向的内存已经被释放了的一种指针。
  + 解决方法：使用完置空，或者使用智能指针。

---

## 三. STL

+ 手写string类

+ 手写





---

## 四.调试

### 1.gdb



### 2.makefile



---

## 五. 链接与编译

### 1.编译与链接过程

+  **一个程序从开始运行到结束的完整过程，你能说出来多少?**

+  **静态链接与动态链接的区别？ 什么是共享库？**

  + 预编译： 运行C预处理器(cpp)将C的源程序 hello.c 翻译成一个ASCII码的中间文件 hello.i. 

    >  `gcc -E hello.c -o hello.i`

    + 处理 “#include” 预编译指令，将文件内容替换到它的位置
    + 删除所有的#define，展开所有的宏定义。 
    + 处理所有的条件预编译指令，如 “#if”、“#endif”、“#ifdef”
    + 删除所有的注释
    + 添加行号和文件标识，便于编译时编译器产生调试用的行号信息

  + 编译：驱动程序运行C编译器(gcc)，将hello.i翻一个一个ASCII汇编语言文件hello.s

    >  `gcc -S hell0.i -o hello.s`

    1. 把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。
    2. 词法分析：将源代码程序输入到扫描机中，将其中的字符序列分割成一系列的记号，类似于有限状态机
    3. 语法分析：对由扫描器产生的记号进行语法分析，产生语法树。语法分析器完成的是对表达式语法层面的分析
    4. 语义分析：语义分析器则对表达式是否有意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定的语义。
    5. 优化：源代码级别的一个优化过程。 
    6. 目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言表示。
    7. 目标代码优化：目标代码优化器对上述的目标机器代码进行优化，寻找合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。

  + 汇编：运行汇编器(as)，将 hello.s 翻译成一个可重定位目标文件 hello.o

    > `gcc -c hell0.s -o hello.o`

    + 汇编器用来将汇编语言源程序转换为机器指令序列。
    + 汇编结果是一个 可重定位目标文件 (如hello.o)，其中包含的是不可读的二进制代码，必须用相应的工具软件来查看其内容。

  + 链接： 运行连接器程序**(ld)**，将**hello.o**和一些必要的系统目标文件组合起来，创建一个可执行文件**prog**:

    > `gcc hell0.o -o hello`

    + 将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接:
      + 静态链接：
        + 对函数库的链接是放在编译时期完成的是静态链接 。 所有相关的目标文件与牵涉到的函数库被链接合成一个可执行文件。 所有需要的函数已复制到相关位置 。Linux下文件名为`libxxx.a`的形式 。
        +  空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本; 
        + 更新困难：每当修改库函数代码，都需要重新进行编译链接形成可执行程序。
        + 运行速度快：可执行程序中具备了所有执行程序所需要的任何内容， 在执行的时候运行速度快。
      + 动态链接：
        + 基本思想是把程序按照模块拆分成各个相对独立部分，库函数的链接载入推迟到程序运行时才链接在一起形成一个完整的程序，动态库文件名`lib**.so`。
        + 共享库：即使每个程序都依赖同一个库，这多个程序在执行时共享同一份副本
        + 更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍
        + 性能损耗：把链接推迟到了程序运行时，所以每次执行程序都需要进行链接

---

+   **介绍一下静态库与动态库的创建与使用**

  + **静态库**

    + **静态库命名规则：** lib + 库的名字 + .a

    + **制作规则：**

      + **生成对应的.o文件：** 参数 -c
      + **将生成的.o文件进行打包：** ar rcs + 静态库的名字(libMyCal.a) + 生成的所有.o文件

    + **发布和使用静态库：**

      + 发布静态库
      + 头文件

    + **例子：**

      <div align = center><img src="../图片/链接2.png" width="250px" /></div>

      + include文件夹存放头文件，src文件夹存放源文件，lib文件夹存放生成的库文件

      + 生成.o文件

        ```bash
        gcc *.c -c -I ../include 
        ```

      + 打包

        ```bash
        ar rcs libMyCal.a *.o
        mv libMyCal.a ../lib
        ```

        <div align = center><img src="../图片/链接3.png" width="210px" /></div>

      + 利用头文件和静态库来运行程序

        ```bash
        gcc main.c lib/libMyCal.a -o sum -I include
        ```

        ```bash
        # -I include头文件
        # -L 库的目录
        # -l 库的名字，去头去尾
        gcc main.c -I include -L lib -l MyCal -o sum
        ```

    + 利用 nm命令 查看静态库内容

      <div align = center><img src="../图片/链接4.png" width="300px" /></div>


  + 动态库

    + **动态库命名规则：** lib + 库的名字 + .so

    + **制作步骤：**

      + **生成与位置无关的代码(.o) ：** 参数 -fPIC -c

        <div align = center><img src="../图片/链接5.png" width="500px" /></div>

        > + 静态库.o在代码段每次位置都相同，所以是与位置有关。
        > + 动态库不会打包到程序中，只有在运行到需要时才会加载到共享库区域，每次加载时放入的位置都不同，所以与位置无关。

      + **将.o打包成动态库：** `gcc -shared  -o libMyCal.so *.o -I include`

    + **例子：**

      + 生成.o文件

        ```bash 
        gcc -fPIC -c *.c -I ../include
        ```

      + 打包成共享库

        ```bash
        gcc -shared  -o libMyCal.so *.o -I ../include
        mv libMyCal.so ../lib
        ```

        <div align = center><img src="../图片/链接6.png" width="250px" /></div>

      + 利用动态库和头文件来运行程序

        ```bash 
        gcc main.c lib/libMyCal.so -o mysum -I include
        
        gcc main.c -I include -L ./lib -l MyCal -o mysum
        ```

        <div align = center><img src="../图片/链接7.png" width="800px" /></div>

        > 没有给动态链接器指定动态库libMyCal.so的路径

    + **解决动态链接库失败的问题**

      + 直接放入系统库目录——不推荐

      + 利用export LD_LIBRARY_PATH=目录 来临时添加，终端关闭后会失效

      + 将上述方法写入bashrc——也不推荐

      + 找到动态连接器的配置文件 

        ```bash
        cd /etc
        sudo vim ld.so.conf
        # 动态库的路径写入配置文件
        /Users/zhangyongbin/Desktop/Cal/lib
        # 更新
        sudo ldconfig -v
        ```


---

+  **gcc 与 g++ 的区别？**

  + 从文件角度：
    + 后缀为 .c 的， gcc 把它当作是C程序， g++当作是C++程序；
    + 后缀为 .cpp 的，两者都会认为是 C++程序
    + 虽然 C++是 C 的超集，但是两者对语法的要求是有区别的 ： printString在 c++ 编译环境下是未定义的
  + 编译和链接的角度：
    + 编译可以用 gcc/g++； g++会自动调用 gcc，二者等价 。
    + 链接可以用 g++或者 gcc-lstce++。 因为 gcc 命令不能自动和 c ++程序使用的库链接，所以通常使用 g++来完成链接 。 

  + extern ”C”与 gcc/g++ 并无关系，无论是 gcc 还是 g++，用 extern”C”时，都是以 C 的命名方式来为symbol命名；否则，都以 C++方式命名。

---

### 2.目标文件

+  **目标文件是什么？有哪几种类型？**
  + 目标文件有三种形式:
    + 可重定位目标文件：包含二进制文件和代码，其形式在编译时和其他可重定位目标文件合并起来，创建一个可执行目标文件
      + 每个.o文件由对应的.c文件生成 
      + 每个.o文件代码和数据地址 都从**0**开始
    + 可执行目标文件：
      + 包含的代码和数据可以被直接复制到内存并被执行
      + 代码和数据地址为虚拟地址空间中的地址
    + 共享目标文件。
      + 特殊的可重定位目标文件，能在 装入或运行时被装入到内存并自动被链接 ，称为共享库文件

---

## 六. 计算机网络

### 0.计算机网络基础

+  **OSI的七层模型是什么？有哪些功能？**
  + 物理层：底层数据传输，如网线;网卡标准。传输的数据称为比特流
  +  数据链路层：定义数据的基本格式，如何传输，如何标识;如网卡MAC地址。 传输的数据称为帧
  + 网络层：定义IP编址，定义路由功能：如不同设备的数据转发。 传输的数据称为包
  + 传输层：端到端传输数据的基本功能;如 TCP、UDP。 传输的数据称为段
  + 会话层：控制应用程序之间会话能力;如不同软件数据分发给不同软件。 
  + 表示层：数据格式标识，基本压缩加密功能。
  + 应用层：各种应用软件，包括 Web 应用。

---

+  **计算机网络体系为什么要按照现有体系进行分层？**
  + 各层之间相互独立：高层不需要知道底层功能是如何实现的，只需知道通过与底层提供的接口就获得所需要的服务
  + 灵活性好：各层的实现无论如何修改，只要提供的功能与接口保持不变，就不会对其他各层以及整个系统产生影响
  + 易于实现和标准化：采取规范的层次结构去组织网络功能与协议，可以将计算机网络复杂的通信过程划分为有序的连续动作与有序的交互过程，使网络系统变得易于设计，实现和标准化

---

+  **网络的七层/五层模型主要的协议有哪些？**

  <img src="../图片/Net4.png" width="400px" />

  +  **ARP(地址解析协议)：实现由 IP 地址得到 MAC 地址。**
    + 主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，A 会通过广播发送 ARP 请求分组，B 收到请求后会发送 ARP 响应分组给 A 告知其 MAC 地址，随后 A 在高速缓存中写入 B 的 IP 地址到 MAC 地址的映射。
  +  **RIP(内部网关协议)：基于距离向量的路由选择协议。**
    + RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。
  +  **IP(互联网协议)：提供一种不可靠，无连接的数据包交付服务。依赖其他层协议进行差错控制。转发路由需要IP**
  +  **ICMP(网际控制报文协议)：ICMP允许主机或路由器报告差错情况和提供相关异常情况的报告。**
    + ICMP报文作为IP层数据报的数据，加上数据报的首部，组成 IP 数据报发送出去。
    + ICMP报文种类：
      + 差错报告报文：（类型值：报文类别）
        + 3：终点不可达
        + 11：时间超过
        + 12：参数问题
        + 5：改变路由
      + 询问报文：
        + 8/0：会送请求或回答
        + 13/14：时间戳请求或回答
    + 应用：
      + ping：测试两台主机之间的连通性。
      + Traceroute：用来跟踪一个分组从源点到终点的路径。
  +  **IGMP(网际组管理协议)：负责IP组播成员管理的协议，用来在IP主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系。**

### 1.网络层





### 2.传输层

+  **是什么是TCP 粘包/拆包 ？ 发生的原因？**

  + 一个完整的业务可能被TCP拆分成多个包发送，也有可能多个包数据到接收方接收时粘成一包，这个就是TCP的拆包和粘包问题。
  + 原因：
    + 因为TCP默认会使用 **Nagle算法** ，此算法会导致粘包问题。	
      + 只有上一个分组得到确认，才会发送下一个分组;
      + 收集多个小分组，在一个确认到来时一起发送。
    + 应用程序写入数据的字节大小大于套接字发送缓冲区大小
    + 进行MSS大小的TCP分段。( MSS=TCP报文段长度-TCP首部长度)

  + 解决方法：
    + 消息定长。
    + 在包尾部增加回车或者空格符等特殊字符进行分割
    + 将消息分为消息头和消息尾。
    + 使用其它复杂的协议，如RTMP协议等。

---

+  **讲讲TCP KeepAlive(保活机制,即心跳包)**
  + TCP连接的双方在连接空闲状态时，如果一方意外崩溃、当机、网线断开或路由器故障，另一方无法得知TCP连接已经失效。另一方并不知道对端的情况，会一直维护这个连接。长时间的积累会导致非常多的半打开连接，造成端系统资源的消耗和浪费，
  + 所以当一个 TCP 连接建立之后，启用 TCP Keepalive 的一端便会启动一个计时器，当这个计时器经过tcp_keep-alive_time时间到达 0 之后便会被发出纯 ACK 包去进行探测。根据对方的回应做出后序操作。

---

+ **传输层的工作内容是什么？**
  + 从通信和信息处理的角度看，运输层向上面的应用层提供通信的服务，属于面向通信部分的最高层，也是用户功能部分的最底层。(只有网络边缘部分的主机协议栈才有运输层)

---

+  **网络层与传输层的区别？**
  + 网络层是为主机之间提供逻辑通信
  + 传输层为应用进程之间提供端到端的逻辑通信

---

+  **运输层有什么重要功能？**
  + 主机中实现多个应用进程分别与另一台主机中的多个应用进程通信，拥有复用与分用的能力
    + 复用： 发送方不同应用进程都能使用同一个运输层协议传输数据（加上适当的首部）
    + 分用： 接收方的运输层在剥去报文的首部后，能把数据正确的交付给对应的目的进程

---

+  **在运输层中端口有什么作用？**
  + 从运输层的角度看，通信的对象是进程，而端口就代表了进程。
    + 端口用一个16位端口号进行标记
    + 只需有本地意义，只标记了本计算机应用层的各个进程

---

+  **一台机器能够使用的端口号上限是多少，是否可以修改?如果想要用的端口超过这个限制怎么办? **
  + 65536个。 TCP的报文头部源端口号和目的端口号的长度是16位，表示 $2^{16}=65536$ 个不同端口号。但0到1023是知名服务端口，所以实际上会少1024个端口号。
  + 而对于服务器来说，端口数目与65536无关，受限Linux可以打开的文件数量，并且通过MaxUserPort 进行配置。

---

+   **封包和拆包你听说过吗?它是基于TCP还是UDP的?**
+  封包和拆包都是基于TCP的。因为TCP是无边界的流传输，所以需要对TCP进行封包和拆包，确保发送和接收的数据不粘连。
    + 封包：在发送数据报时为每个TCP数据包加上一个包头，将数据报分为包头和包体两个部分。包头是一个固定长度的结构体，里面包含该数据包的总长度。 
  + 拆包：接收方在接收到报文后提取包头中的长度信息进行截取。

---

+  **用户数据报协议UDP(User Datagram Protocol) 有什么特点？**

  1. 面向报文的，对应用层交付的报文，不合并也不拆分，加上首部之后直接发送

     > + 报文太长，交给IP层之后，IP层可能会分片，降低IP层效率
     > + 报文太短，交给IP层之后，显得IP数据报首部相对长度太长，也降低IP层效率

  2. 无连接的：发送消息之前不需要建立连接，减少了开销与发送数据之前的延迟
  3. 尽最大努力交付：不保证可靠交付，因此主机之间不需要维持复杂的连接状态表
  4. 没有拥塞控制：因此网络拥塞时不会使源主机的发送速率降低，符合多媒体通信要求
  5. 支持一对一，一对多，多对一，多对多的交互通信
  6. 首部开销小，只有8字节，比TCP的20字节小

---

+  **介绍一下UDP的首部格式**
  + UDP有两个字段：  首部字段 和 数据字段。首部字段有8个字节，由4个字段组成，每个字段占两个字节：
    + 源端口： 源端口号。需要给对方回信时使用，不用时赋予0
    + 目的端口： 目的端口号。 在终点交付报文时必须使用
    + 长度：UDP数据报的长度，最小值为8
    + 检验和：检验UDP 数据报在传输过程中是否出错，出错则丢弃

---

+  **在进行UDP编程的时候，一次发送多少bytes好?**
  + IP数据报大于1500字节(MTU)时需要分片。建议将UDP的数据控制在1472字节以下(1500-ip头-UDP头).
  + 进行Internet编程时则不同，因为Internet上的路由器可能会将MTU设为不同的值. 如果我们假定MTU为1500来发送数据的,而途经的某个网络的MTU值小于1500字节,那么系统将会使用一 系列的机制来调整MTU值,使数据报能够顺利到达目的地,这样就会做许多不必要的操作.
  + 鉴于Internet上的标准MTU值为576字节。建议在进行Internet的UDP编程时. 最好将UDP的数据长度控件在548字节(576-8-20)以内

---

+  **为什么需要TCP协议？**
  + IP层是不可靠，不保证网络包的按需交付与数据完整性。
  + 如果需要保证传输过程可靠，则需要上层的TCP协议来负责，TCP能保证接收端收到的网络包是按序，无损坏的

---

+  **介绍一下 传输控制协议TCP(Transmission Control Protocol)，它有什么特点？**

  + TCP是面向连接的运输层协议，在无连接，不可靠的IP层网络服务基础上提供 **可靠交付** 的 **基于字节流** 的传输层通信协议

    + 面向连接： TCP连接只支持点对点的，只有两个端点

    + 可靠的：传输过程中无论网络链路怎么变化，TCP第一能保证报文能达到接收端

    + 面向字节流： 虽然应用程序与TCP以数据块的形式交互，但TCP把上层交付下来的数据仅看成是一连串无结构的字节流

      > TCP 不保证接收方应用程序数据块与发出的数据块大小对应，但字节流必须完全一样。

  + 传输过程的特点：

    + TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文⻓ 度是应用进程给出的）
    + TCP 可把太⻓的数据块划分短一些再传送
    + TCP 也可等待积累有足够多的字节后再构成报文段发送出去

---

+  **TCP报文段首部有哪些字段？**
  + 从前往后分别是
    + 源端口号 (2 bytes)，目的端口号 (2 bytes)
    + 序号  (4 bytes)
    + 确认号  (4 bytes)
    + 数据偏移， 保留，紧急URG，确认ACK，推送PSH，复位RST，同步SYN，终止FIN，窗口 (2 bytes)
    + 检验和  (2 bytes)，紧急指针 (2 bytes)
    + 选项字段 ，填充(首部是4字节的整数倍)
+   **TCP 头部有哪些信息？具体什么作用？**
+   **常见TCP的连接状态有哪些?**

---

+  **介绍一下TCP的连接的端点与协商内容**

  + TCP面向的是套接字，连接端点称为socket或者插口

    <div align  = center>socket = ip地址 + 端口号 </div>

  + 建立TCP连接时需要通信两端达成三个信息的共识

    + socket：即IP地址与端口号
    + 序列号：用来解决乱序问题
    + 窗口大小：用作流量控制

---

+  **如何确定一个TCP连接**
  + 源地址，源端口，目的地址，目的端口，这四元组能确定一个连接
    + 源地址，目的地址 在IP头部，通过IP协议将报文发送到具体主机
    + 源端口，目的端口 在TCP头部，通过TCP协议将报文发送到具体进程

---

+  **有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？**

  + 最大TCP连接数 = 客户端 IP 数 * 客户端的端口数

  + 对 IPv4， IP 数最多为 $2^{32}$ ，端口数最多为$2^{16}$，则最大 TCP连接数为 $2^{48}$。但远不能到达这个上限值。

    > + 文件描述符限制，Socket 都是文件，要通过 ulimit 配置文件描述符的数目;
    > + 内存限制

---

+  **什么是半连接队列？**
  + 服务器第一次收到客户端的 SYN 之后处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个 **队列** 里，这就是 **半连接队列** 。
  + 对应自然有 **全连接队列**，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

---

+ **TCP与UDP有哪些区别？**
  1. 连接：
     +  TCP面向连接传输协议，传输数据之前需建立连接，UDP无连接，即可传输
  2. 服务对象
     + TCP点对点
     + UDP都行
  3. 传输方式
     + TCP 面向连接，基于字节流，无边界，但保证有序与可靠
     + UDP直接发送包，有边界，但可能出现丢包与乱序
  4. 可靠性
     + TCP是可靠交付数据，有序，不丢失，无损伤
     + UDP尽最大努力传输，不保证可靠性
  5. 拥塞控制，流量控制
     + TCP有拥塞控制与流量控制机制，保证数据传输的安全性
     + UDP没有，就算网络拥堵也不影响发送速率
  6. 首部开销
     + TCP首部较长，没有使用选项字段时为20字节，开销较大
     + UDP首部只有8字节，固定不变，开销较小
  7. 分片方法
     + TCP是在传输层进行分片，当数据大于MSS，TCP会进行分片，若中途丢失一个分片，只需重发对应分片即可
     + UDP是在网络层进行分片，当数据大于MTU，IP会进行分片，若中途丢失一个分片，在实现可靠传输的 UDP 时需重传整个的数据包，所以通常UDP报文应该小于MTU
  8. 应用场景
     + TCP是可靠交付，用于
       + FTP文件传输
       + HTTP/HTTPS
     + UDP 无连接，可随时发送，处理简单高效
       + 包总量较小的通信，如DNS，SNMP
       + 视频，音频等多媒体通信
       + 广播通信

---

+  **为什么UDP头部没有 首部长度 字段，而TCP有？**
  + TCP有可变长的 选项 字段，所以需要记录长度
  + UDP首部大小固定，无需记录

---

+  **为什么 UDP 头部有「包⻓度」字段，而 TCP 头部则没有「包⻓度」字段呢?**
  + TCP 是计算负载数据⻓度:  TCP数据的⻓度 =  IP总⻓度 - IP首部⻓度 - IP首部⻓度
  + UDP其实也可以这么计算，但可能是为了网络设备硬件设计和处理方便，首部⻓度需 **4** 字节整数倍。利用字段可能可能是为了补全。

---

+ **TCP连接建立过程中要解决哪些问题？**
+ **TCP链接建立过程**

---

+  **TCP建立连接中维护「序列号」的作用？**

  + 接收方可以去除重复的数据; 
  + 接收方可以根据数据包的序列号按序接收; 
  + 可以标识发送出去的数据包中， 哪些是已经被对方收到的

---

+  **TCP建立连接为什么是三次握手，而不是两次或四次？**

  + TCP 建立连接时，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序 列号。序列号能够保证数据包不重复、不丢弃和按序传输。
  + 不使用「两次握手」和「四次握手」的原因:
    + 「两次握手」:无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号; 
    + 「四次握手」:三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

---

+   **为什么客户端和服务端的初始序列号 ISN 是不相同的**

  + 如果序列号相同，那么就无法分辨出该报文是不是历史报文，如果历史报文被新的连接接收了，则会产生数据错乱
  + 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收。

---

+  **初始序列号 ISN(Initial Sequence Number) 是如何随机产生的?**

  + ISN = M + F (localhost, localport, remotehost, remoteport)

    > + M 是一个计时器，这个计时器每隔 4 毫秒加 1。
    > + F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。

---

+  **既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢?**

  > +  **MTU :** 一个网络包的最大⻓度，以太网中一般为 1500 字节;
  > +  **MSS :** 除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大⻓度;

  + 将 TCP 的整个报文(头部 + 数据)交给 IP 层进行分片的话，如果一个 **IP** 分片丢失，整个 **IP** 报文的所有分片都得重传。 因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。
  + 当接收方发现 TCP 报文(头部 + 数据)的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时 后，就重会发「整个 TCP 报文(头部 + 数据)」。非常没有效率。
  + 为了达到最佳的传输效能， TCP 协议在建立连接的时候通常要协商双方的 **MSS** 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 **MSS** 为单位，而不用传所有 的分片，大大增加了重传的效率。

---

+  **什么是SYN攻击？**
  + 因为 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到 一个 SYN 报文，就进入 SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 **SYN** 接收队列(未连接队列)，使得服务器不能为正常用户服务。

---

+  **如何避免SYN攻击？**
  + 修改 Linux 内核参数，控制队列大小和当队列满时应做相应的处理。
    + 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。超出处理能时，对新的 SYN 直接回报 RST，丢弃连接。
    + tcp_syncookies 的方式可以应对 SYN 攻击的方法: net.ipv4.tcp_syncookies = 1

---

+ **TCP链接释放的过程**
+  **释放连接为什么需要四次挥手？**
  + 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。
  + 服务器收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。
  + 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。

---

+  **对于FIN_WAIT_2，CLOSE_WAIT状态和TIME_WAIT状态?你知道多少?**

  + FIN_WAIT_2:

    + 半关闭状态。
    + 发送断开请求一方还有接收数据能力，但已经没有发送数据能力。

  +  CLOSE_WAIT状态:

    + 被动关闭连接一方接收到FIN包会立即回应ACK包表示已接收到断开请求。

    + 被动关闭连接一方如果还有剩余数据要发送就会进入CLOSED_WAIT状态。

  +  TIME_WAIT状态:

    + 又叫2MSL等待状态。 如果客户端直接进入CLOSED状态，如果服务端没有接收到最后一次ACK包会在超时之后重新再发FIN包，此时因为客户端已经CLOSED，所以服务端就不会收到ACK而是收到RST。
    + 所以 TIME_WAIT状态目的是防止最后一次握手数据没有到达对方而触发重传FIN准备的。 在2MSL时间内，同一个socket不能再被使用，否则有可能会和旧连接数据混淆(如果新连接和旧 连接的socket相同的话)。

---

+   **MSL 与 TTL 的区别是什么？**

   +  MSL 是 Maximum Segment Lifetime，表示任何报文在网络上存在的最⻓时间，超过这个时间报文将被丢弃。
   +  因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，表示经过的最大路由数，每经过一个路由器就减 1，为 0 则被丢弃，同时发送 ICMP 报文通知源主机。
   +  MSL 的单位是时间，而 TTL 是经过路由跳数。往往 **MSL** 应该要大于等于 **TTL** 消耗为 **0** 的 时间，以确保报文已被自然消亡。

---

+   **为什么需要 TIME_WAIT 状态?**

   +  防止旧连接的数据包，经过 2MSL 这个时间，足以让两个方向上的数据包都被丢弃，使得数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。

   +  保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；

      > 若客户端四次挥手的最后一个 ACK 报文如果在网络中被丢失了，此时如果客户端 TIME-WAIT 过短或没有，则就直接进入了 CLOSED 状态了，那么服务端则会一直处在 LASE_ACK 状态。

---

+  **为什么 TIME_WAIT 等待的时间是 2MSL?**
  +  网络中可能存在来自发送方的数据包，当这些数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 **2** 倍的时间。
  + 在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。**Linux** 系统停留在 **TIME_WAIT** 的时 间为固定的 **60** 秒。

---

+  **可以解释一下 ** **RTO** **，** **RTT** **和超时重传分别是什么吗?**
  + 超时重传： 发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况:
    + 发送的数据没能到达接收端，所以对方没有响应。 
    + 接收端接收到数据，但是ACK报文在返回过程中丢失。 
    + 接收端拒绝或丢弃数据。
  + RTO：从上一次发送数据，因为长期没有收到ACK响应，到下一次重发之间的时间。就是重传间隔。
    + 通常每次重传RTO是前一次重传间隔的两倍，计量单位通常是RTT。例:1RTT，2RTT，4RTT， 8RTT......
       重传次数到达上限之后停止重传。
  + RTT：数据从发送到接收到对方响应之间的时间间隔，即数据报在网络中一个往返用时。大小不稳定。

---

+ **TIME_WAIT 过多的原因，有什么危害以及解决方法?**

  +  原因：
    
    +  短时间内出现过多的TCP链接释放
    
  + 危害：

    +  客户端TIME_WAIT过多，就会导致端口资源被占用，被占满就会导致无法创建新的连接。
    +  服务端只监听一个端口，但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是当服务端出现大量 TIME_WAIT 时，系统资源被占满时，会导致处理不过来新的连接。

  +  处理方法：

     +  调整系统内核参数：

        +   修改系统默认的 TIMEOUT 时间 tcp_fin_timeout
        +  减少保持TIME_WAIT套接字的最大数量 tcp_max_tw_buckets
        +  增加可用端口范围

     +  调整短链接为长链接

        +  短连接：连接->传输数据->关闭连接

           > 短连接是指SOCKET连接后发送后接收完数据后马上断开连接。

        +  长链接：连接->传输数据->保持连接 -> 传输数据-> ... ->关闭连接

           > 长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。

---

+   **服务器出现大量close_wait的连接的原因是什么?有什么解决方法?**

  + 原因:

    + 服务器内部业务处理占用了过多时间，都没能处理完；或者还有数据需要发送；或者服务器的业务逻辑有问题，没有执行close()方法 
    + 服务器的父进程派生出子进程，子进程继承了socket，收到FIN的时候子进程处理但父进程没有处理该信号，导致socket的引用不为0无法回收

  + 危害：socket资源会被耗尽

  + 处理方法: 

    + 停止应用程序

    + 修改程序里的bug

---

+  **TCP如何实现的可靠传输？** 
  + 首先，采用三次握手来建立TCP连接，四次握手来释放TCP连接，从而保证建立的传输信道是可靠的。
  + 其次，TCP采用了连续ARQ协议来保证数据传输的正确性，使用滑动窗口协议来保证接方能够及时处理所接收到的数据，进行流量控制。
  + 最后，TCP使用慢开始、拥塞避免、快重传和快恢复来进行拥塞控制，避免网络拥塞。

---

+  **介绍一下停止等待协议**
  + **“**停止等待**”**就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。
  + 发送方如何知道对方正确收到消息的？
    + 每一个已发送的分组都设置了一个超时计时器。 只要在超时计时器到期之前收到了相应的确认，就撤销该超时计时器，继续发送下一个分组 ，否则重发
  + 如何知道收到 了重复的分组，需要丢弃呢？
    + 每一个发送的分组都进行编号。接收方收到了编号相同的分组，则认为收到了重复分组，会进行丢弃，并回送确认
    + 发送方也为发送的确认也进行编号，指示该确认是对哪一个分组的确认。
    + 接收方根据确认其编号，可以确定它是对哪一个分组的确认，避免重发发送。若为重复的确认，则将其丢弃。
  + 改进：为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用流水线传输。

---

+  **介绍一下 连续ARQ协议**
  + 发送方设置
    + 发送方设置发送窗口，将发送窗口中的分组连续发送出去，而不用等待对方的确认，提高了信道利用率
    + 发送方没接收到一个确认，就会把发送窗口向前滑动一个分组的位置
  + 接收方设置
    + 不需要对每一个分组逐个发送确认，只需对按序到达的最后一个分组发送确认，表示到这个分组为止的所有分组都已正确收到。
  + 回退N机制：如果发送方发送了前 5 个分组，而中间的第 **3** 个分组丢失了。这时接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次。 
  + 优点：容易实现，即使确认丢失也不必重传
  + 缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。

---

+  **介绍一下TCP的流量控制方法**
  + TCP利用滑动窗口实现流量控制。窗口用来暂时存放字节流。发送方和接收方各有一个窗口。接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。
  + 发送方：发送窗口内的字节都允许被发送，窗口左部的字节已经发送并且收到了确认，就将窗口右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态。
  + 接收方：接收窗口内的字节都允许被接收，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。接收窗口只会对窗口内最后一个按序到达的字节进行确认。

---

+  **介绍一下TCP的拥塞控制原理**

  + 流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。否则导致网络拥塞程度更高，重发分组数目也会更多

  + TCP 主要通过四个算法来进行拥塞控制: 慢开始、拥塞避免、快重传、快恢复。

  + 发送方需要维护一个叫做拥塞窗口(cwnd)的状态变量

    >  拥塞窗口 与 发送方窗口 的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。

  + **慢开始与拥塞避免**

    + 发送的最初执行慢开始，令 cwnd = 1，只能发送 1 个报文段；当收到确认后，将 cwnd 加倍
    + 设置一个慢开始⻔限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1
    + 如果出现了**==超时==**，则令 ssthresh = cwnd / 2，然后重新执行慢开始。

  + 快重传与快恢复

    + 在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已接收到 M1，M2，此时收到 M4，应当发送对 M2 的确认。 
    + 在发送方，如果收到三个重复确认，则知道下一个报文段丢失，应执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。
    + 在这种情况下，只是**==丢失==**个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。

  > 区分好 两者的区别和使用场景。

---

### 3.应用层

+ HTTP和HTTPS有哪些不同的地方呢？ARP协议的作用，哪些过程会使用这个协议呢？在一个广域网中，我如何利用该协议来找到目标主机的MAC地址并返回给源主机呢？(大概是这么问的吧，回答的时候我也说了一下IP协议)

+ HTTP状态码

---

+  **应用层的功能是什么？**
  + 应用进利用程相应的应用层协议来使用下层网络所提供的通信服务。

---

+  **介绍一下域名解析系统 DNS**
  + DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。DNS 可以使用 UDP 或 TCP 进行传输，端口号都为 53。多数情况使用 UDP ，所以域名解析器和域名服务器必须自己处理超时和重传来保证可靠性。使用TCP 情况：
    + 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。
    + 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。

---

+ **介绍一下域名解析系统的工作方式：**
  +  主机向本地域名服务器的查询一般都是采用递归查询。向上递归，查完后返回
  + 本地域名服务器向根域名服务器的查询的迭代查询。每次询问完都给反馈
    1. 输入域名后，浏览器先检查缓存中是否有域名映射的ip地址，有解析结束。
    2. 若无，则检查操作系统缓存(如Windows的hosts)中有无解析过的结果，有解析结束。
    3. 若无，则查找本地DNS解析器缓存，有解析结束。
    4. 若无，首先找本地DNS服务器，查询到相对应的IP地址映射或者缓存信息则结束。
    5. 若无，则根据本地DNS服务器设置的转发器进行查询：
       + 未用转发模式：
         + 本地DNS就把请求发至根DNS进行迭代查询，根DNS服务器收到请求后会判断域名(.com)由谁授权管理，返回负责该顶级域名服务器的一个IP。
         + 本地DNS服务器收到IP后，联系负责.com域的服务器，若无法解析，它会找下一级DNS服务器地址给本地DNS服务器。本地DNS服务器收到地址就找域名域服务器，重复上面动作，直至找到域名对应的主机
       + 使用转发模式：
         + 本地DNS服务器把请求转发至上一级DNS服务器，让它进行解析，若不能解析，把请求转至上上级，以此循环，直至找到，然后原路回来。最后把结果返回给本地DNS服务器，DNS服务器再返回给客户机

---

+  **为什么域名解析基本上使用 UDP 协议？**
  + 因为UDP快! UDP的DNS协议只要一个请求、一个应答就好了。TCP需要三次握手建立连接
  + 但UDP 最大只支持 512 字节的数据，如果数据超过则使用TCP

---

+  **为什么区域传送使用 TCP 协议？**
  + 因为TCP协议可靠性好。从主DNS上复制内容需要进行可靠传输，而且UDP有大小限制，最大只支持 512 字节的数据。万一同步的数据大于512字节就无法使用UDP了。

---

+  **介绍一下DNS的负载均衡策略**
  + 一个网站有大量用户请求，请求的资源位于同一台机器，这台机器随时可能会蹦。处理办法就是DNS负载均衡技术
  + 原理是在DNS服务器中为同一个主机名配置多个IP地址，在应答DNS查询时，DNS服务器对每个查询 **将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果** ，将客户端的访问引导到不同的机器上去，使得不同的客户端访问不同的服务器，达到负载均衡的目的。

---

+  **介绍一下动态主机配置协议DHCP**
  + 提供了即插即用的连网方式，让DHCP服务器自动分配IP 地址等信息，不再需要用户手动配置 。
    1. 客户端发送 Discover 报文，目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。
    2. DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息
    3. 客户端选择了某个 DHCP 服务器提供的信息，那就发送 Request 报文给该 DHCP 服务器。
    4. HCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。

---

+  **应用层中分别基于TCP，UDP的协议**

  + TCP：
    + FTP：定义了文件传输协议，使用21端口. 
    + Telnet：它是一种用于远程登陆的端口,23端口 
    + SMTP：定义了简单邮件传送协议，服务器开放的是25号端口。 
    + POP3：它是和SMTP对应，POP3用于接收邮件。

  + UDP：
    + DNS：用于域名解析服务，用的是53号端口 
    + SNMP：简单网络管理协议，使用161号端口
    + TFTP(Trival File Transfer Protocal)：简单文件传输协议，69

---

+ **简单介绍一下HTTP协议**
  + 超文本传输协议HTTP是一个简单的请求—响应协议，运行在TCP之上，指定了客户端可能发送给服务器端的消息类型与响应类型，请求和响应消息以ASCII形式给出；而消息内容则具有一个类似MIME的格式。 

---

+  **介绍一下 HTTP 请求报文与响应报文**

  + 客户端发送请求报文给服务器，服务器进行处理请求报文中的信息，并将处理结果放入响应报文中返回给客户端。

  + 请求报文结构：

    + 第一行是包含了请求方法、URL、协议版本；
    + 接下来的多行都是请求首部 Header，每个首部是以 首部名称: 值 来显示。
    + 一个空行用来分隔首部和内容主体 Body
    + 最后是请求的内容主体

    ```http
    GET http://www.example.com/ HTTP/1.1
    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
    Accept-Encoding: gzip, deflate
    Accept-Language: zh-CN,zh;q=0.9,en;q=0.8
    Cache-Control: max-age=0
    Host: www.example.com
    If-Modified-Since: Thu, 17 Oct 2019 07:18:26 GMT
    If-None-Match: "3147526947+gzip"
    Proxy-Connection: keep-alive
    Upgrade-Insecure-Requests: 1
    User-Agent: Mozilla/5.0 xxx
    
    param1=1&param2=2
    ```

  + 响应报文结构：

    + 第一行包含 协议版本、状态码以及描述
    + 接下来多行也是首部内容
    + 一个空行分隔首部和内容主体
    + 最后是响应的内容主体

    ```http
    HTTP/1.1 200 OK
    Age: 529651
    Cache-Control: max-age=604800
    Connection: keep-alive
    Content-Encoding: gzip
    Content-Length: 648
    Content-Type: text/html; charset=UTF-8
    Date: Mon, 02 Nov 2020 17:53:39 GMT
    Etag: "3147526947+ident+gzip"
    Expires: Mon, 09 Nov 2020 17:53:39 GMT
    Keep-Alive: timeout=4
    Last-Modified: Thu, 17 Oct 2019 07:18:26 GMT
    Proxy-Connection: keep-alive
    Server: ECS (sjc/16DF)
    Vary: Accept-Encoding
    X-Cache: HIT
    
    <!doctype html>
    <html>
    <head>
        <title>Example Domain</title>
    	// 省略... 
    </body>
    </html>
    ```

---

+  **介绍一下URL？**

  + http 使用 URL（ **U**niform **R**esource **L**ocator，统一资源定位符）来定位资源，是 URI（**U**niform **R**esource **I**dentifier，统一资源标识符）的一个子集，URL 在 URI 的基础上增加了定位能力。

    > URI 还包含 URN（Uniform Resource Name，统一资源名称），它知识用来定义一个资源的名称，并不具备定位该资源的能力。

---

+  **介绍一下HTTP请求行中有哪些方法？**
  + HTTP1.0 定义了三种请求方法: GET, POST 和 HEAD方法。
  +  HTTP1.1 新增了六种请求方法:OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。
    1. GET：请求指定的页面信息，并返回实体主体。
    2. HEAD：获取报文首部。不返回报文实体主体部分。主要用于确认 URL 的有效性以及资源更新的日期时间等。
    3. POST：向指定资源提交数据进行处理请求。数据被包含在请求体中。
    4. PUT：上传文件，但存在安全性问题，一般不使用该方法。
    5. DELETE：请求服务器删除指定的页面。
    6. CONNECT：HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。
    7. OPTIONS：允许客户端查看服务器的性能。
    8. TRACE：回显服务器收到的请求，主要用于测试或诊断。
    9. PATCH：是对 PUT 方法的补充，用来对已知资源进行局部更新 。

---

+  **GET与POST的区别是什么？**

  1. get是获取数据，post是修改数据

  2. get把请求的数据放在url上， 以分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内(requrest body)

  3. get提交的数据最大是2k( 限制实际上取决于浏览器)， post理论上没有限制。

  4. GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据)； POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。

  5. GET请求会被浏览器主动缓存，而POST不会，除非手动设置。

  6. 本质区别:GET是幂等的，而POST不是幂等的

     > + 这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。
     >
     > + 因为get 请求是幂等的，在网络不好的隧道中会尝试重试。如果用get请求增数据，会有重复操作的风险

---

+  **POST 方法比 GET 方法安全?**
  + 有人说POST 比 GET 安全，因为数据在地址栏上不可见。然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。
  + 要想安全传输，就只有加密，也就是 HTTPS。

---

+  **GET** **与** **POST** **传递数据的最大长度能够达到多少呢?**
  + 很多文章都说GET方式提交的数据最多只能是1024字节，而实际上 HTTP 协议规范没有对URL长度进行限制
    + 限制是特定的浏览器及服务器对它的限制，比如IE对URL长度的限制是2083字节(2K+35字节）
    + 浏览器无限制时，这时限制服务器的操作系统，若url太长，服务器可能会因为安全方面的设置从而拒绝请求或者发生不完整的数据请求。
  + post 理论上讲是没有大小限制的，HTTP协议规范也没有进行大小限制，但实际上post所能传递的数据量 大小取决于服务器的设置和内存大小

---

+  **POST** **方法会产生两个** **TCP** **数据包?你了解吗?**
  + POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。
  + HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。
  + 所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。

---

+  **介绍一下 HTTP 的状态码有哪些？**
  + 1XX：信息
    + **100 Continue** ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。
  + 2XX：成功
    + **200 OK**
    + **204 No Content** ：请求已经成功处理，返回的响应报文不包含实体的主体部分。
  + 3XX：重定向
    + **301 Moved Permanently** ：永久性重定向
    + **302 Found** ：临时性重定向
    + **303 See Other** ：和 302 有着相同的功能，但采用 GET 方法获取资源
    + **304 Not Modified** ： 如果不满足请求行中的条件就返回这个
  + 4XX：客户端错误
    + **400 Bad Request** ：请求报文中存在语法错误。
    + **401 Unauthorized** ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
    + **403 Forbidden** ：请求被拒绝。
    + **404 Not Found**
  + 5XX：服务器端错误
    + **500 Internal Server Error** ：服务器正在执行请求时发生错误。
    + **503 Service Unavailable** ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求

---

+  **HTTP 有哪些首部字段？**
  + 通用首部字段、请求首部字段、响应首部字段和实体首部字段。
  + 具体见[HTTP 首部字段](https://github.com/ZYBO-o/Skill-Accumulation/blob/main/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-HTTP%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.md#%E9%80%9A%E7%94%A8%E9%A6%96%E9%83%A8%E5%AD%97%E6%AE%B5)

---

+  **HTTP长连接和短连接的区别**
  + 在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接， 任务结束就中断连接。
  + 在HTTP/1.1起，默认使用长连接，用以保持连接特性。

---

+  **为什么服务器会缓存这一项功能?如何实现的?**
  + 原因：
    + 缓解服务器压力;
    + 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。
  + 实现：
    + 让代理服务器进行缓存
    +  让客户端浏览器进行缓存

---

+  **一个TCP连接可以对应几个HTTP请求?**
  + 如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

---

+  **一个TCP 连接中 HTTP 请求发送可以一起发送么(比如一起发三个 请求，再三个响应一起接收)?**

  + HTTP/1.1 中单个 TCP 连接在同一时刻只能处理一个请求，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。

    >  HTTP/1.1 存在 Pipelining 技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的.

  + 在 HTTP/1.1 时代，浏览器是如何提高页面加载效率的呢?

    + 维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求。
    + 和服务器建立多个 TCP 连接。

  + HTTP2 中由于 Multiplexing 特点的存在，多个 HTTP 请求可以在同一个 TCP 连 接中并行进行。

---

+  **浏览器对同一 Host 建立TCP连接到的数量有没有限制?**
  + 有。Chrome 最多允许对同一个 Host 建立六个 TCP 连接。不同的浏览器有一些区别。
  + 如果资源是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP2，如果能的话就使用 Multiplexing 功能在这个连接上进行多路传输。
  + 如果都不能用，浏览器就会在一个 HOST 上建立多个 TCP 连接，连接数量的最大限制取决于浏览器设置

---

+  **浏览器在与服务器建立了一个** **TCP** **连接后是否会在一个** **HTTP** **请求完成后断开?什么情况下会断开?**
  + 在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开链接。这样开销代价过大。
  + HTTP/1.1 把 Connection 头写进标准，并且默认开启持久连接，除非请求中写明 Connection: close，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，当请求报头中声明 Connection: close 才会在请求完成后关闭连接

---

+  **在浏览器中输入url地址后显示主页的过程?**
  1. 根据域名，进行DNS域名解析; 
  2. 拿到解析的IP地址，建立TCP连接; 
  3. 向IP地址，发送HTTP请求; 
  4. 服务器处理请求;
  5. 返回响应结果; 
  6. 关闭TCP连接; 
  7. 浏览器解析HTML; 
  8. 浏览器布局渲染;

---

+ **键入网址到网⻚显示，期间发生了什么?**
  1. 查询**DNS**，获取域名对应的**IP**。 （DNS使用了UDP协议）
     + 检查本地hosts文件是否有这个网址的映射，如果有，就调用这个IP地址映射，解析完成。
     + 如果没有，则查找本地DNS解析器缓存
     + 如果没有，查找填写或分配的首选DNS服务器，称为本地DNS服务器。
     + 则此DNS服务器就会把请求转发至上一级DNS服务器，如果上一级DNS服务器不能解析，则 继续向上请求。最终将解析结果依次返回本地DNS服务器，本地DNS服务器再返回给客户机，查询完成。
  2. 客户端与服务器建立**TCP**连接(三次握手)
  3. 客户机发送**HTTP**请求报文:
     + 应用层:客户端发送HTTP请求报文
     + 传输层:切分⻓数据，并确保可靠性。
     + 网络层:进行路由
     + 数据链路层:传输数据
     + 物理层:物理传输bit 
  4. 经过物理层→数据链路层→网络层→传输层→应用层到达服务器端，服务器解析请求报文，发送HTTP响应报文。 
  5. 客户端收到后解析HTTP响应报文
  6. 浏览器开始显示HTML 
  7. 浏览器重新发送请求获取图片、CSS、JS的数据。

---

+  **HTTP中缓存的私有和共有字段?知道吗?**

  + private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。

    `Cache-Control: private`

  + public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中

    `Cache-Control: public`

---

+  **HTTP** **中有个缓存机制，但如何保证缓存是最新的呢?(缓存过期机制)**

  + max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。

  + max-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。

    `Cache-Control: max-age=31536000`

  + Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。

    `Expires: Wed, 04 Jul 2012 08:26:05 GMT`

  + 在 HTTP/1.1 中，会优先处理 max-age 指令; 

---

+  **HTTP** **如何禁用缓存?如何确认缓存?** 

  + HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。

    + 禁用缓存： no-store 指令规定不能对请求或响应的任何一部分进行缓存

      `Cache-Control: no-store`

    + 确认缓存： no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。

      `Cache-Control: no-cache`

---

+  **HTTP1.0和HTTP1.1的区别?**
  +  **长连接** ：HTTP 1.1支持长连接（Persistent Connection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启`Connection： keep-alive`，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。
  +  **缓存处理**：在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。
  +  **带宽优化及网络连接的使用**：HTTP1.0中，存在一些浪费带宽的现象，例如[客户端]()只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
  +  **错误通知的管理**：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
  +  **Host头处理**：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。

---

+   **HTTP1.1和 HTTP2.0的区别？**
  +  **新的二进制格式**： HTTP1.1的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。
  +  **多路复用**，即连接共享，即每一个request都是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。
  +  **头部压缩**，HTTP1.1的头部（header）带有大量信息，而且每次都要重复发送；HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。
  +  **服务端推送**：服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求。

----

+  **什么是HTTPS，为什么需要HTTPS？**
  + 原因：HTTP 有以下安全性问题：
    - 使用明文进行通信，内容可能会被窃听；
    - 不验证通信方的身份，通信方的身份有可能遭遇伪装；
    - 无法证明报文的完整性，报文有可能遭篡改。
  + HTTPS 并不是新协议，而是让 HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信，也就是说 HTTPS 使用了隧道进行通信。
  + 通过使用 SSL，HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）。

---

+  **HTTPS 和 HTTP的区别**

  + |              | HTTP               | HTTPS                                   |
    | ------------ | ------------------ | --------------------------------------- |
    | 端口         | 80                 | 443                                     |
    | 安全性       | 无加密，安全性较差 | 有加密机制，安全性较高                  |
    | 资源消耗     | 较少               | 由于加密处理，资源消耗更多              |
    | 是否需要证书 | 不需要             | 需要                                    |
    | 协议         | 运行在TCP协议之上  | 运行在SSL协议之上，SSL运行在TCP协议之上 |

---

+  **什么是 SSL/TLS?**
  + SSL代表安全套接字层。是用于加密和验证应用程序(如浏览器)和Web服务器之间发送的数据的协议。
  + SSL/TLS协议的基本思路是采用公钥加密法，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。
  + SSL/TLS协议作用：认证用户和服务，加密数据，维护数据的完整性。

---

+  **HTTPS是如何保证数据传输的安全，整体的流程是什么? (SSL是怎么工作保证安全的)**

  1. 客户端向服务器端发起SSL连接请求;
  2. 服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥
  3. 客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端 
  4. 服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密
  5. 进行数据传输，服务器和客户端双方用公有的相同的对称秘钥对数据进行加密解密，保证在数据收发过程中的安全，即使第三方获得数据包，也无法对其进行加密，解密和篡改。

  + 数字签名、摘要是证书防伪非常关键的武器。 
    + “摘要”就是对传输的内容，通过hash算法计算出一段固定长度的串。
    + 通过发送方的私钥对这段摘要进行加密，加密后得到的结果就是“数字签名”

---

+  **为什么有的时候刷新页面不需要重新建立** **SSL** **连接?**
  + TCP 连接有的时候会被浏览器和服务端维持一段时间，TCP 不需要重新建立，SSL 自然也会用之前的。

---

+  **SSL 中的认证中的证书是什么?了解过吗**
  + 通过使用 **证书** 来对通信方进行认证。
  + 数字证书认证机构(CA，Certificate Authority)是客户端与服务器双方都可信赖的第三方机构。
  + 服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。
  + 进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签 名进行验证，如果验证通过，就可以开始通信了。

---

+  **如何保证公钥不被篡改?**
  + 将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。
  + 公钥加密计算量太大，如何减少耗用的时间?
    + 每一次对话(session)，客户端和服务器端都生成一个"对话密钥"(session key)，用它来加密信息。"对话钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。

---

+  **非对称密钥加密你了解吗?优缺点?**
  + 对称密钥加密(Symmetric-Key Encryption)，加密和解密使用同一密钥。
    + 优点:运算速度快
    + 缺点:无法安全地将密钥传输给通信方

---

+  **非对称密钥加密你了解吗?优缺点?**
  + 非对称密钥加密，又称公开密钥加密(Public-Key Encryption)，加密和解密使用不同的密钥。
  + 公钥所有人都可以获得，发送方获得接收方的公钥之后，使用公钥进行加密**， **接收方接收后使用私钥解密。
  + 非对称密钥除了用来加密，还可以用来进行签名。因为私钥无法被其他人获取，因此发送方使用其私钥进行签名，通信接收方使用发送方的公钥对签名进行解密，就能判断这个签名是否正确。
    + 优点:可以更安全地将公开密钥传输给通信发送方;
    + 缺点:运算速度慢

---

+  **HTTPS 采用的加密方式有哪些?是对称还是非对称?**
  + HTTPS 采用混合的加密机制
    + 使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性，之后使用对称密钥加密进行通信来保证通信过程的效率。
    + 确保传输安全过程(其实就是rsa原理):
      1. Client给出协议版本号、一个客户端生成的随机数(Client random)，以及客户端支持的加密方法。
      2. Server确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数(Server random)。
      3. Client确认数字证书有效，然后生成呀一个新的随机数(Premaster secret)，并使用数字证书中的公钥，加密这个随机数，发给Server。
      4. Server使用自己的私钥，获取Client发来的随机数(Premaster secret)。
      5. Client和Server根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”(session key)，用来加密接下来的整个对话过程。

---

+  **Cookie是什么？**
  + 引入原因：
    + HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。
  + 是什么：
    + Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，在浏览器之后向同一服务器再次发起请求时被携带上，告知服务端两个请求是否来自同一浏览器。由于请求携带 Cookie 数据，因此会带来额外的性能开销
    + Cookie 曾用于客户端数据的存储，因为当时没有其它合适的存储办法，随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。

---

+  **Cookie有什么作用/用途？**
  + 话状态管理(如用户登录状态、购物车、游戏分数或其它需要记录的信息)
  +  个性化设置(如用户自定义设置、主题等)
  + 浏览器行为跟踪(如跟踪分析用户行为等)

---

+  **Session是什么？**
  + 除了可以将用户信息通过 Cookie 存储在用户浏览器，也可以利用 Session 存储在服务器端，这样更加安全。
  + Session 可以存储在服务器上的文件、数据库或内存中。也可以存储在 Redis 这种内存型数据库中，效率会更高。

---

+  **使用 Session 维护用户登录状态的过程是怎么？**

  1. 用户进行登录时，提交包含用户名，密码的表单，放入 HTTP 请求报文中；
  2. 服务器验证用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
  3. 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文后将该 Cookie 值存入浏览器中；
  4. 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

  >  注意： Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜 到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如 转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密 码，或者使用短信验证码等方式。

---

+  **Session 的工作原理是什么？**
  + 工作原理是客户端登录完成之后，服务器会创建对应的 session，创建完之后，会把 session 的 id 发送给客户端
  + 客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 session id
  + 服务器拿到 session id 之后，在内存找到与之对应的 session 这样就可以正常工作了。

---

+  **Cookie与Session 的区别与对比**
  + Cookie是客户端保持状态的方法。
    + 简单理解就是存储由服务器发至客户端并由客户端保存的一段字符串。为了保持会话，服务器在响应客户端请求时将Cookie字符串放在Set-Cookie下，客户端收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别。
    + Cookie在客户端的保存形式有两种：
      + 会话Cookie：会话Cookie将服务器返回的Cookie字符串保持在内存中，关闭浏览器之后自动销毁
      + 持久Cookie：持久Cookie则存储在客户端磁盘，有效期内客户端再次请求时都可以直接从本地取出，可以被多个浏览器代理所共享
  + Session是服务器保持状态的方法
    + Session保存在服务器上的数据库、或文件或内存中，每个用户有独立的 Session 记录用户的操作。
    + 可以理解为每个用户有一个独一无二的Session ID 作为 Session文件的Hash键，通过这个值可以锁定具体的Session 结构的数据，这个Session结构中存储了用户操作行为。

---

+  **Cookie 与 Session 的怎么选择**
  + Cookie 只能存储 ASCII 码字符串，Session 可以存储任何类型的数据，在考虑数据复杂性时首选 Session；
  + Cookie 存储在浏览器中容易被恶意查看。若非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
  + 对于大型网站，若用户所有的信息都存储在 Session 中，开销非常大，不建议将所有用户信息都存储到 Session 中

---

+  **知道SQL注入攻击吗?**
  + 攻击者在HTTP请求中注入恶意的SQL代码，服务器使用参数构建数据库SQL命令时，恶意SQL被一起构造，并在数据库中执行。
  +  如用户登录，输入用户名 lianggzone，密码 ‘ or ‘1’=’1 ，如果此时使用参数构造的方式，就会出现
     `select * from user where name = ‘lianggzone’ and password = ‘’ or ‘1’=‘1’ `。不管用户名和密码是什么，使查询出来的用户列表不为空。
  + 如何防范SQL注入攻击使用预编译的PrepareStatement是必须的，但是一般从两个方面同时入手：
    + Web端
      + 有效性检验。
      + 限制字符串输入的长度。
    +  服务端
      + 不用拼接SQL字符串。
      + 使用预编译的PrepareStatement。 
      + 有效性检验。(为什么服务端还要做有效性检验?第一准则，外部都是不可信的，防止攻击者绕过 Web端请求)
      + 过滤SQL需要的参数中的特殊字符。比如单引号、双引号。

---

+  **Linux系统是如何收发网络包的？**
  + 发送流程：
    + 首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层 协议的类型， 比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。
    +  到了网络层，则取出 IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机 后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。
    + 传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据拷 ⻉到 Socket 的接收缓冲区。
    + 最后，应用层程序调用 Socket 接口，从内核的 Socket 接收缓冲区读取新到来的数据到应用层。 至此，一个网络包的接收过程 就已经结束了，你也可以从下图左边部分看到网络包接收的流程，右边部分刚好反过来，它是网络包发送的流程。
  + 接收流程：
    + 首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，Socket 层会将应用层数据拷⻉到 Socket 发送缓冲区中。
    + 接下来，网络协议栈从 Socket 发送缓冲区中取出数据包，并按照 TCP/IP 协议栈从上到下逐层处理。 如果使用的是 TCP 传输协 议发送数据，那么会在传输层增加 TCP 包头，然后交给网络层，网络层会给数据包增加 IP 包，然后通过查询路由表确认下一跳的 IP，并按照 MTU 大小进行分片。 分片后的网络包，就会被送到网络接口层，在这里会 通过 ARP 协议获得下一跳的 MAC 地址，然后增加帧头和帧尾，放到发包队列中。
    +  这一些准备好后，会触发软中断告诉网卡驱动程序，这里有新的网络包需要发送，最后驱动程序通过 DMA，从发 包队列中读取 网络包，将其放入到硬件网卡的队列中，随后物理网卡再将它发送出去。

---

+  **DDos** **攻击了解吗?**

  + 拒绝服务 (DoS) 攻击是一种恶意尝试，它在短时间内发起大量请求，耗尽服务器的资源，无法响应正常的访问，造成网站实质下线。

  + DDOS 里面的 DOS 是 denial of service（停止服务）的缩写，表示这种攻击的目的，就是使得服务中断。最前面的那个 D 是 distributed （分布式），表示攻击不是来自一个地方，而是来自四面八方，因此更难防。

  + DDos 预防:

    + 限制SYN/ICMP流量：路由器上配置SYN/ICMP的最大流量来限制SYN/ICMP封包所能占有的最高频宽，出现大量的超过所限定的SYN/ICMP流量时，说明不是正常的网络访问

    + 网站请求IP过滤 ：通过限制单位时间内的POST请求、404页面等访问操作，来过滤掉次数过多的异常行为。
    + 关闭不必要的服务/端口

---

+  **XSS** **攻击是什么?(低频)**

  + XSS跨站脚本攻击：攻击者想尽一切方法将一段脚本内容放到目标网站的目标浏览器上解释执行

  + 如何防范XSS攻击

    + 前端，服务端，同时需要字符串输入的长度限制。 

    + 前端，服务端，同时需要对HTML转义处理。将其中的”<”,”>”等特殊字符进行转义编码。

      >  防 XSS 的核心是必须对输入的数据做过滤处理。

---

+  **CSRF** **攻击?你知道吗?**

  + 跨站点请求伪造，指攻击者通过跨站请求，以合法的用户的身份进行非法操作。
  + 可以这么理解：攻击者盗用你的身份以第三方网站发送恶意请求。CRSF能做的事情包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息。

  + 如何防范？
    +  **验证请求来源地址；** 在HTTP Header中有一个字段Referer，它记录了HTTP请求的来源地址。如果Referer是其他网站，就有可能是CSRF攻击，则拒绝该请求。但是，服务器并非都能取到Referer。很多用户出于隐私保护的考虑，限制了Referer的发送。
    +  **关键操作添加验证码；** 通常情况下，验证码能够很好的遏制CSRF攻击，但是很多情况下，出于用户体验考虑，验证 码只能作为一种辅助手段，而不是最主要的解决方案。
    +  **在请求地址添加 token 并验证。** 在HTTP请求中进行token验证，如果请求中没有token或者token内容不正确，则认为CSRF攻 击而拒绝该请求。

---

+  **文件上传漏洞是如何发生的?你有经历过吗? 如何预防**
  + 文件上传漏洞，指的是用户上传一个可执行的脚本文件，并通过此脚本文件获得了执行服务端命令的能力。
  +  许多第三方框架、服务，都曾经被爆出文件上传漏洞，比如很早之前的Struts2，以及富文本编辑器等 等，可被攻击者上传恶意代码，有可能服务端就被人黑了。
  + 预防：
    + 判断文件类型。在判断文件类型的时候，可以结合使用MIME Type，后缀检查等方式。因为对于上传文件，不能简单地通过后缀名称来判断文件的类型，因为攻击者可以将可执行文件的后缀名称改为图片或其他后缀类型，诱导用户执行。
    + 对上传的文件类型进行白名单校验，只允许上传可靠类型。
    + 上传的文件需要进行重新命名，使攻击者无法猜想上传文件的访问路径，将极大地增加攻击成本， 同时向shell.php.rar.ara这种文件，因为重命名而无法成功实施攻击。
    + 限制上传文件的大小。
    + 单独设置文件服务器的域名。









---

## 七.操作系统

### 1.Linux 命令

+ linux 中查看监听网络端口命令，more和cat的区别

+ linux 改密码命令 改权限命令

+  如何结束一个进程， -9 是什么含义、

+ ps的底层实现(我按照自己的理解，讲了一下PCB的机制，然后说大概是扫描了一下PCB的[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)，面试官好像挺满意的)。

+ 对于大文件，为什么CP比MV慢很多
+ 如果rm以及rm -f一个正在被使用的文件，会发生什么

### 2.进程与线程

+ 两个进程会存放在相同的内存地址吗？讲几种进程调度的算法？进程的状态有哪几种？哪些操作会使进程从用户态到内核态呢？
+ Linux进程地址空间分布
+ Linux内存管理方法，页面置换[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)，逻辑地址和物理地址的转换
+ 生产-消费者模型，伪代码，用条件变量，注意使用while()替代if()判断是否满足条件
+ C++20里的协程，所以又问了我协程相关的东西，包括内核线程和用户态线程之类的。
+ 为什么要区分内核和用户态
+ linux怎么管理进程内存？
+ 怎么快速定位linux下占用资源很大的程序单元
+  哪些时候会发生上下文切换，上下文切换过程中经历了什么

---

+  **进程，线程和协程的区别和联系**
  + 定义：
    + 进程： 进程是在内存中运行着的程序，是资源分配和拥有的基本单位
    + 线程：线程是轻量级的进程，是最小的执行单位
    + 协程：用户态的轻量级线程，线程内部调度的基本单位
  + 区别：
    1. **切换情况：**
       + 进程：进程CPU环境的保存以及 新调度的进程CPU环境的设置 ；涉及栈、寄存器、页表和文件句柄等
       + 线程：保存和设置程序计数器，少量寄存器和栈的内容
       + 协程：先将寄存器上下文和栈保存，等切换回来的时候再进行恢复
    2. **切换者**
       + 进程：操作系统
       + 线程：操作系统
       + 协程：用户
    3. **切换过程**
       + 进程：用户态—>内核态—>用户态
       + 线程：用户态—>内核态—>用户态
       + 协程：只有用户态
    4. **调用栈**
       + 进程：内核栈
       + 线程：内核栈
       + 协程：用户栈
    5. **拥有资源**
       + 进程：CPU资源，内存资源，文件资源，句柄等
       + 线程：程序计数器，寄存器，栈等
       + 协程：自己的寄存器上下文和栈
    6. **系统开销**
       + 进程：切换涉及到虚拟地址空间，内核栈与硬件上下文，开销较大
       + 线程：切换时只需保存和设置少量的寄存器内容，开销较小
       + 协程：直接操作栈则基本没有内核切换的开销，可以不加锁访问全局变量，所以上下文切换非常快
    7. **通信方面**
       + 进程：需要借助操作系统内核
       + 线程：线程间通信只需直接读写进程数据段，如全局变量来进行通信
       + 协程：共享内存，消息队列等

---

+   **线程与进程的比较**
  +  进程： 进程是在内存中运行着的程序，是资源分配和拥有的基本单位
  +  线程：线程是轻量级的进程，是最小的执行单位
  +  对比：
     +  线程启动速度快，轻量级
     +  线程的系统开销小
     +  线程使用有一定难度，需要处理数据一致性问题 
     +  同一线程共享的有堆、全局变量、静态变量、指针，引用、文件等，而独自占有栈

---

+   **介绍一下进程控制块PCB，及其中的内容**
  + 每个进程在内核中都有一个进程控制块(PCB)来维护进程相关的信息，Linux内核的进程控制块是 task_struct结构体。
  + **PCB**内部重要成员
    1. 进程标识符
    2. 进程当前状态
    3. 进程优先级
    4. 进程资源清单
    5. 进程相应的程序和数据地址，以便把PCB与其程序和数据联系起来。
    6. 进程同步与通信机制等等

---

+  **你知道哪些进程？**

  + 孤儿进程：

    + 父进程已经终止的进程**,**它们的父进程都改变为**init**进程。这些进程自身变成孤儿进程，被init进程收养。

    > 由init进程收养的进程终止时不会成为僵尸进程。init被编写成无论何时只要有一个子进程终止，init就会调用 一个wait函数取得其终止状态。

  + 僵尸进程：

    + 一个已经终止、但是其父进程尚未对其进行善后处理(获取终止子进程的有关信息、释放它仍占用的资源)的进程被称为僵死进程(zombie)，终止进程的残留资源(PCB)存放于内核中

    > 特别注意，僵尸进程是不能使用kill命令清除掉的。因为kill命令只是用来终止进程的，而僵尸进程已经终止。
    >
    > + 如果父进程没有调用wait、waitpid，怎么杀死僵尸进程
    >   + 查看进程：ps -ef | grep defunct ： 1 running, 94 sleeping, 0 stopped, **0 zombie**
    >   + 一般僵尸进程很难直接kill掉，可以kill僵尸父进程。父进程死后，僵尸进程成为”孤儿进程”，过继给1号进程init，init始终会负责清理僵尸进程．它产生的所有僵尸进程也跟着消失。
    >   + ps -e -o ppid,stat | grep Z | cut -d " " -f2 | xargs kill -9

  + 守护进程：

    + 是 Linux 的一种⻓期运行的后台服务进程 ，也称「精灵进程」。常⻅的 httpd、 named、sshd 等服务都是以守护进程 Daemon 方式运行的

---

+  **什么是惊群效应**
  + 惊群现象就是多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），当等待的事件发生，它会唤醒等待的所有进程（或者线程），但是最终却只可能有一个进程（线程）获得这个事件的“控制权”，其他进程（线程）获取失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群。
  + 现象的影响：
    + 这种效应使得系统对用户进程/线程频繁地做无效的调度，上下文切换，系统性能大打折扣。
    + 而且为了确保只有一个线程得到资源，用户必须对资源操作进行加锁保护，进一步加大了系统开销。
  + 例子：
    + Linux 2.6 之前。 主进程创建了socket、bind、listen之后，fork() 出来多个进程，每个子进程都开始循环处理（accept）这个listen_fd。 每个进程都阻塞在accept上，当一个新的连接到来时候，所有的进程都会被唤醒，但是其中只有一个进程会接受成功，其余皆失败，重新休眠。
    + Linux 2.6 之后的版本，Linux内核已经解决了accept（）函数的“惊群”现象，大概的处理方式就是，当内核接收到一个客户连接后，只会唤醒等待队列上的第一个进程（线程），所以如果服务器采用accept阻塞调用方式，在最新的linux系统中已经没有“惊群效应”了

---

### 3.死锁

+ 死锁的四个必要条件



+ 举例子讲解如何解决死锁



---

## 八.数据库



+ truncate 和delete区别



+ 索引分类和原理----B+树，具体分析



+ 数据库锁有哪些，造成原因



+ 如果在数据库上进行了误操作该怎么处理



+ 数据库sga问题



+ B树和B+树的区别，ACID, 索引种类，explain关键字



+ 介绍一下数据库索引(B+树、哈希索引、LSM树之类)



+ 索引的类别和使用场景
+  Mysql如何实现主从一致性



---



## 九.网络编程相关

+ 讲讲非阻塞socket
+ 文件读经历了哪些过程

---



### 1.socket

-  **TCP进行socket编程的步骤**
  - 服务端和客户端初始化 socket ，得到文件描述符;
  - 服务端调用 bind ，将绑定在 IP 地址和端口;
  - 服务端调用 listen ，进行监听;
  - 服务端调用 accept ，等待客户端连接；
  - 客户端调用 connect ，向服务器端的地址和端口发起连接请求;
  - 服务端 accept 返回用于传输的 socket 的文件描述符;
  - 客户端调用 write 写入数据;服务端调用 read 读取数据;
  - 客户端断开连接时，会调用 close ，那么服务端 read 读取数据的时候，就会读取到了 EOF ， 待处理完 数据后，
  - 服务端调用 close ，表示连接关闭。

-  **服务器端会维护哪两个队列？** 
  
  - 未完成连接队列(SYN 队列):接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态; 
  - 已完成连接队列(Accpet 队列):已完成 TCP 三次握手过程，处于 ESTABLISHED 状态;
  
-  **服务器端进行TCP连接(socket连接)时，内核的工作流程**
  - 当客户端发送的SYN请求报文到达后，插入到SYN 队列，随后给对方发送ACK确认报文
  - 当接收到客户端的ACK确认报文后，应用程序从Accpet 队列中取出已完成连接的socket

-  **socket的各个步骤对应 TCP 握手中的哪些阶段？**

  - 客户端初始化 socket ，调用 connect 后，进入SYS-SENT状态，是第一次握手阶段
  - 服务器端初始化 socket ，调用 bind 绑定在 IP 地址和端口，调用 listen 进行监听后，进入Listen状态
  - 服务器端在接收到客户端的 SYN 请求报文后， 调用 accept ，等待客户端连接，并回复ACK确认报文，进入 SYN-RCVD状态
  - 客户端接收到ACK确认报文后，connect函数返回文件操作符，回复ACK确认报文，进入established状态
  - 服务器端收到对方的ACK确认报文后，accpet API 函数返回 文件操作符，进入established状态

-  **为什么一个socket可以accept多次？**

  - 输入参数 fd 是从 socket， bind， listen 中沿用下来的 socket 句柄值，是在指定的端口处监昕所有的连接请求。
  - 调用 accept() 是从 socket fd 的请求队列抽取第一个连接信息，创建新的同类型 socket 句柄 fd 来进行后续操作。
  - 两个fd 是不同的，所以能 accept 多次

-  **客户端调用close后，连接是断开的流程是什么?**

  - 就是四次挥手流程

-  **IO有哪两种操作？**

  - 同步IO：必须等待 IO 操作完成后，控制权才返回给用户进程 。 
  - 异步IO：无须等待 IO 操作完成，就将控制权返回给用户进程 。 

-   **网络IO发生时，设计哪些对象与操作？**

  - 会涉及两个系统对象：调用这个 IO 的 进程，系统内核。
  - 当一个 read操作发生时，会经历两个阶段:
    - 等待数据准备; 
    - 将数据从内核拷贝到进程中。

-  **简单介绍一下4中IO模型。**

  - 阻塞IO：阻塞是指 IO 操作需要彻底完成后才返回到用户空间

    > 阻塞 IO 模型的特点就是：在 IO 执行的两个阶段(等待数据和拷贝数据)都被阻塞了 。

  - 非阻塞IO：非阻塞是指 IO 操作被调用后立即返回给用户一个状态值， 不需要等到 IO 操作彻底完成。

    > `fcntl( fd, F_SETFL, O_NONBLOCK );` 来设置socket成为非阻塞IO

  - 多路IO复用（事件驱动IO）：多路 IO复用 可以监视多个描述符， 一旦某个描述符就绪( 读就绪或写就绪)，能够通知程序进行相应的读写操作。 

    > 调用API后整个进程会被阻塞，而且存在两个系统调用(select与revcfrom)，如果连接数不多，不能体现优势。

  - 异步IO：

    - 用户角度：用户进程发起 read操作之后，立刻就可以开始去做其他的事;
    - 内核角度：当它收到一个异步的 read请求操作之后，首先会立刻返回，所以不会对用户进程产生任何阻塞。 然后，内核会等待数据准备完成，然后将数据拷贝到用户内存中，当这一切完成后，内核会给用户进程发送一个信号，返回 read操作已完成的信息 。

  > + 阻塞 IO、非阻塞 IO 及多路 IO 复用都属于同步 IO。
  > + 非阻塞 IO在执行 recvfrom 候，若内核的数据没有准备好，不会阻塞进程 。 但当内核中数据准备好时， recvfrom 会将数据从内核拷贝到用户内存中，这时进程仍被阻塞。 
  > + 异步 IO 不同， 当进程发起 IO 操作之后，就直接返回，直到内核发送一个信号，告诉进程 IO 已完成，整个过程中进程完全没有被阻塞。

---

### 3.IO复用

-  **介绍一下 select 系统调用设计的函数**

  ```c++
  #include <sys/select.h>
  void FD_ZERO(fd_set *set); 						//把文件描述符集合里所有位清0
  void FD_CLR(int fd, fd_set *set); 		//把文件描述符集合里fd清0
  int  FD_ISSET(int fd, fd_set *set); 	//测试文件描述符集合里fd是否置1
  void FD_SET(int fd, fd_set *set); 		//把文件描述符集合里fd位置1
  
  struct timeval {
    	long tv_sec; /* seconds */  
    	long tv_usec; /* microseconds */
  };
  
  int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, 
             struct timeval *timeout);
  ```

  **参数：**

  + nfds： 指定被监听的文件描述符的总数。通常设置为被监听的所有fd中的最大值加1，因为fd从0开始计数的。

  + readfds：  监控有读数据到达文件描述符集合，传入传出参数

  + writefds： 监控写数据到达文件描述符集合，传入传出参数

  + exceptfds： 监控异常发生达文件描述符集合,如带外数据到达异常，传入传出参数

  + timeout： 定时阻塞监控时间，3种情况

    1. NULL，永远等下去

    2. 设置timeval，等待固定时间

    3. 设置timeval里时间均为0，检查描述字后立即返回，轮询

  **返回值：**

  + 成功： **所监听的所有 监听集合中，满足条件的总数**
  + 失败： 返回 -1 并设置errno


---

+  **简单介绍一下select调用过程。**

  1. 在进行 `socket, bind, listen` 后，得到连接请求描述符 `listenfd`。设置数组`client[FD_SETSIZE]`存放文件描述符，全部初始化为 -1。

  2. 设置 存放文件描述符集合 `fd_set rset`，使用 `FD_ZERO(rset)` 进行清零，使用 `FD_SET(listenfd)` 将 `listenfd` 加入集合

  3. 设置 `maxfd = listenfd + 1` ，进行 while 循环，将 `rset` 赋给临时的` readset`，调用 `select` 函数

     > `select (maxfd, &readset,NULL, NULL, NULL)`

  4. 等待 `select` 有返回值时，得到就绪的文件操作符数目 `nready`，先进行判断是否合理，然后利用 `FD_ISSET(listenfd, &rset)`  判断是否有新的连接
  5. 如果有，则调用 `accept` ，返回连接后的文件描述符 `connfd` 。使用 `FD_SET(connfd, &readset); ` 将 `connfd` 放入 `readset` 集合中。
  6. 遍历 `client` 数组，将 `connfd` 放入合适位置，`nready--` 。最后更新 `maxfd`
  7. 随后遍历 client 数组，找出其中的 文件描述符， 使用 `FD_ISSET(sockfd, &rset)` 操作，判断是否存在读事件，如果是，则继续进行任务操作，如 read。  `nready--` 。
  8. 当 `nready == 0` 时，while 循环跳出，结束。关闭 `listenfd`。 

---

+  **介绍一下 poll 系统调用函数**

  ```c
  #include <poll.h>
  
  struct pollfd {
      int fd; /* 文件描述符 */
  		short events; /* 监控的事件：主要是 POLLIN,POLLOUT,POLLERR */
  		short revents; /* 监控事件中满足条件返回的事件，由内核填充 */
  };
  
  int poll(struct pollfd *fds, nfds_t nfds, int timeout);
  ```

  **参数：**

  + fds： pollfd结构类型的数组，它指定所有我们感兴趣的文件描述符上发生的可读，可写和异常等事件。
  + nfds： 指定被监听时间集合fds的大小。
  + timeout： 毫秒级等待
    + -1：阻塞等待，#define INFTIM -1         Linux中没有定义此宏
    + = 0：立即返回，不阻塞进程
    + \> 0：等待指定毫秒数，如当前系统时间精度不够毫秒，向上取值

  **返回值：**

  + 成功： 所监听的所有 监听集合中，满足条件的总数
  + 失败： 返回 -1 并设置errno

---

+  **简单介绍一下poll调用过程。**

  + 定义 pollfd 结构体数组 `struct pollfd client[1024]`，将第一个`client[0]`设置fd与events设置为listenfd与POLLIN，其余fd为-1 ，设置maxi = 1。

  + 进行循环，调用 poll 函数， 返回就绪文件描述符个数，查看`client[0]`是否为 POLLIN事件(`client[0].revents & POLLIN`) 

    > `nready = poll(client, maxi, -1);`

  + 如果是，调用accept得到新的连接文件描述符connfd，将其存放到client数组中合适的位置。更新maxi,nready--。

  + 遍历前面`1-maxi`个client数组，找出就绪的文件描述符，查看是否为POLLIN事件，如果事，则进行下面的任务处理，nready--。

  + 当 `nready == 0` 时，while 循环跳出，结束。关闭 `listenfd`。

---

+ **介绍一下 epoll 系统调用函数**

  + epoll_create 函数：创建一个epoll句柄，参数size用来告诉内核监听的文件描述符的个数

    ```c++
    #include <sys/epoll.h>
    
    int epoll_create(int size);
    ```

    + 参数：
      + size：监听数目(告诉Linux内核创建多大的epoll模型)，创建多大结点的红黑树，只是建议值，
    + 返回值：
      + 成功返回 文件描述符，指向红黑树的根
      + 失败返回 -1

  + epoll_ctl 函数：控制某个epoll监控的文件描述符上的事件：注册、修改、删除。

    ```c++
     #include <sys/epoll.h>
    
    struct epoll_event {
    			__uint32_t events; /* Epoll events */
    			epoll_data_t data; /* User data variable */
    };
    
    typedef union epoll_data {
        void *ptr;
        int fd;					//与epoll_ctl函数中的fd对应
        uint32_t u32;
        uint64_t u64;
    } epoll_data_t;
    
    int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
    /*
    	epoll_event中的 events:
    	EPOLLIN ：	表示对应的文件描述符可以读（包括对端SOCKET正常关闭）
    	EPOLLOUT：	表示对应的文件描述符可以写
    	EPOLLPRI：	表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）
    	EPOLLERR：	表示对应的文件描述符发生错误
    	EPOLLHUP：	表示对应的文件描述符被挂断；
    	EPOLLET： 	将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)而言的
    	EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
    */
    ```

    + 参数：
      + epfd ： epoll_create成功返回的文件描述符，即红黑树树根
      + op ： 在红黑树树上进心增删改：
        + EPOLL_CTL_ADD (注册新的fd到epfd)
        + EPOLL_CTL_MOD (修改已经注册的fd的监听事件)
        + EPOLL_CTL_DEL (从epfd删除一个fd)
      + fd ： 具体需要操作的文件描述符
      + event： 告诉内核需要监听的事件(往往只需要 events 与 data.fd)
    + 返回值：
      + 成功返回 0
      + 失败返回 -1

  + epoll_wait函数： 等待所监控文件描述符上有事件的产生，类似于 select() 调用。

    ```c++
    #include <sys/epoll.h>
    
    int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
    ```

    + 参数：
      + epfd ： epoll_create成功返回的文件描述符，即红黑树树根

      + events ： 是一个传出参数数组

        > epoll_ctl中是传入变量的地址，这个变量初始化好就行
        >
        > epoll_wait中是传入数组，传出满足事件的文件描述符，每个元素都是epoll_event结构体

      + maxevents ： 告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，

      + timeout ：是超时时间

        +  -1： 阻塞
        +  0： 立即返回，非阻塞
        +  \>0： 指定毫秒

    + 返回值：
      + 成功返回有多少文件描述符就绪
      + 时间到时返回0，
      + 出错返回-1

---

+  **简单介绍一下 epoll 的调用过程**

  1. 通过 `epoll_create` 函数创建 epoll 模型，返回红黑树的根结点作为文件描述符 efd。

  2. 创建epoll_event事件与数组(`struct epoll_event tep, ep[OPEN_MAX]; `)，将tep的event设置为EPOLLIN，data.fd 设置为 listenfd。利用 epoll_ctl 函数将 listen 与 tep 添加到 efd 的红黑树中

     >  `res = epoll_ctl(efd, EPOLL_CTL_ADD, listenfd, &tep); `

  3. 循环，将 数组 ep 代入epoll_wait函数等待文件描述符就绪，当就绪后，返回就绪的文件描述符数目

     > ` nready = epoll_wait(efd, ep, OPEN_MAX, -1); ` 

  4. 循环 ep 数组中前 nready 个元素，查看是否是EPOLLIN事件(`ep[i].events & EPOLLIN`) 

  5. 如果是，则查看是否为listenfd 就绪(`ep[i].data.fd == listenfd`)，如果是，则调用accpet函数，返回新的连接文件描述符 connfd，重新赋值给 tep ，利用 epoll_ctl 函数将tep 加入红黑树中

  6. 如果不是listenfd 就绪，则取出，赋值给sockef，利用它来完成其他任务操作。

---

+ **介绍一下 epoll 的两种触发模式**

  + **Level Triggered (LT 水平触发)** ：epoll的默认触发方式，既支持阻塞模式，也支持非阻塞模式，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。一次性读写完未全部完成，那么下次调用 epoll_wait()时，还会通知在上次没读写完的文件描述符上继续读写

  + **Edge Triggered (ET 边缘触发)** ： 只支持非阻塞模式，当被监控的文件描述符上有可读写事件发生时，epoll_wait() 会通知处理程序去读写。一次性全部读写完未完成，那么下次调用epoll_wait()时，不会通知，即只会通知一次，直到该文件描述符上出现第二次可读写事件。

    > 最好是利用边缘触发，使用非阻塞fd，套上while循环将数据一次性读写完成，这样效率更高。

---

+  **在ET模式下当多个连接同时到达时该怎么处理？**

  + 理论上如果多个连接同时到达，服务器的TCP就绪队列瞬间积累多个就绪连接，由于是边缘触发模式，epoll只会通知一次，accept只处理一个连接，导致TCP就绪队列中剩下的连接都得不到处理。

  + 解决办法是用while循环包住accept调用，处理完TCP就绪队列中的所有连接后再退出循环。如何知道是否处理完就绪队列中的所有连接呢？accept返回-1并且errno设置为EAGAIN就表示所有连接都处理完。

---

+  **nigix的实现中多个连接同时到达如何处理？**
  + nigix 中 ，accept函数调用使用水平触发的fd，就是出于对丢失连接的考虑，所以不存在丢失连接的问题。
  + 但是若系统中有大量不需要读写的就绪文件描述符，而它们每次都会返回，会大大降低处理程序检索自己关心的就绪文件描述符的效率。

---

+ **使用Linux epoll模型，水平触发模式；当socket可写时，会不停的触发socket可写的事件，如何处理？**
  + 平时不要把该描述符放进event_poll结构体中，当需要写该fd的时候，调用epoll_ctl把fd加入eventpoll里监听，可写的时候就往里写，写完再次调用epoll_ctl把fd移出event_poll，这种方法在发送很少数据的时候仍要执行两次epoll_ctl操作，有一定的操作代价
  + 改进一下就是：平时不要把该描述符放进event_poll结构体中，需要写的时候调用write或者send写数据，如果返回值是EAGAIN（写缓冲区满了），那么这时候才执行第一种方法的步骤。

---

+ **比较IO复用 select，poll，epoll 的区别**

  + select、 poll和 epoll都是多路 IO 复用机制。 可以监视多个描述符， 一旦某个描述符就绪，会通知程序进行相应的读写操作。 但它们本质上都是同步 IO，因为它们都需要在读写事件就绪后自己负责进行读写，是阻塞的。

  + select的优缺点：

    + select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。
    + select()对于超时值提供了更好的精度，而 poll()是精度较差。
    + select能监听的文件描述符个数受限于FD_SETSIZE,一般为1024
    + select采用的是轮询模型，如果链接客户端过多，会大大降低服务器响应效率

  + poll的优缺点：

    + 可以修改文件描述符的上限数目，优于select
    + 将监听集合 和 返回集合 实现了分离，不像select那么麻烦，搜索范围更小
    + poll在应付大数目的文件描述符时速度更快，对于 select 来说内核需要检查大量描述符对应的set中的每一个比特位，比较费时。
    + 但还是需要将数组全部变量，找出已连接的文件描述符，而不是直接返回满足的文件描述符数组。

  + epoll 的优点

    + 支持ET触发模式，其余两者只支持LT。

    + 不是使用轮询的方式，不会随着fd数目的增加效率下降。只有活跃可用的fd才会调用callback函数；selet 与 poll 调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。

    + 使用 mmap加速内核与用户空间的消息传递

      > 3者都需要内核把fd消息通知给用户空间，如何避免不必要的内存拷贝就显得尤为重要 。 
      >
      > epoll 通过内核 与用户空间 mmap 处于同一块内存实现的 。
      >
      > poll将传入的 pollfd数组拷贝到内核空间，因为拷贝操作和数组长度相关，时间上来看，这是一个 O(n)操作

---

+ Libevent如何处理IO事件，信号事件，和定时事件








---

## 十一.Redis 









---

## 十二.WebServer项目相关

+  **介绍一下你的WebServer项目**
  + 这是一个服务器项目

---

+  **介绍一下服务器程序中的事件处理模式**
  + 简单介绍：
    + Reactor模式：利用I/O复用，让主线程调用 epoll_wait 等待 socket 上有数据可读与可写。当epoll_wait 通知主线程后，主线程将 socket 事件放入请求队列，唤醒的线程来处理数据的读写与后续的业务逻辑
    + Proactor模式：利用 异步I/O aio_read 与 aio_write 让内核来进行 socket 的读写操作，等操作完成后内核通知主线程，主线程将唤醒工作线程来处理后续的业务逻辑与事件注册
    + 同步IO模拟Proactor模式： 主线程调用 epoll_wait 等待 socket 上有数据可读与可写。当epoll_wait 通知主线程后，主线程将数据读完之后封装成请求队列中的元素，唤醒工作线程完成后续的逻辑业务与事件注册。
  + **Reactor模式**
    + 要求主线程 (I/O处理单元) 只负责监听文件描述上是否有事件发生，有则立即将该事件通知工作线程(逻辑单元)，将socket可读可写事件放入请求队列，交给工作线程处理。除此之外，工作线程不做任何实质性的工作。读写数据，连接新的连接，处理客户请求接在工作线程完成。
    + 使用同步 I/O 模型实现的工作流程：
      1. 主线程 在epoll 内核事件表中注册 socket 的读就绪事件
      2. 主线程调用 epoll_wait 等待 socket 上有数据可读
      3. 有数据可读时，epoll_wait 通知主线程，主线程将 socket 可读事件放入请求队列
      4. 睡眠在请求队列中的某个工作线程被唤醒，它从socket 读取数据，并处理客户请求，然后往 epoll 事件表中注册 socket 上的写就绪事件
      5. 主线程调用 epoll_wait 等待 socket 可写
      6. socket 可写时， epoll_wait 通知主线程，主线程将 socket 可写事件放入请求队列
      7. 睡眠在请求队列中的某个工作线程被唤醒，它往 socket 上写入服务器处理客户请求的结果
  +  **Proactor模式：**
    + 将所有I/O操作都交给主线程和内核处理(读写)，工作线程只负责业务逻辑。
    + 使用异步I/O模型实现的工作流程：
      1. 主线程调用 aio_read 函数向内核注册 socket 上的读完成事件，并告诉内核 用户读缓冲区的位置，以及读操作完成时如何通知应用程序，可用信号
      2. 主线程继续处理其他逻辑
      3. 当 socket 上的数据被读入用户缓冲区后，内核将向应用程序发送信号，通知数据可用
      4. 应用程序预先定义的信号处理函数选择一个工作线程来处理客户请求。处理完成之后调用 aio_write 函数向内核注册 socket 上的写完成事件，并告诉内核 用户写缓冲区的位置，以及写操作完成时如何通知应用程序
      5. 主线程继续处理其他逻辑
      6. 当用户缓冲区数据写入 socket 后，内核将向应用程序发送信号，通知数据已发送
      7. 应用程序预先定义的信号处理函数选择一个工作线程做善后工作，比如是否关闭socket
  +  **同步I/O模拟Proactor模式：**
    + 主线程执行数据读写操作，完成之后主线程向工作线程通知这一"完成事件"。从工作线程的角度看，它们只需对读写的结果进行逻辑处理。
    + 使用同步 I/O 模型模拟出Proactor模式的工作流程如下：
      1. 主线程 在epoll 内核事件表中注册 socket 的读就绪事件
      2. 主线程调用 epoll_wait 等待 socket 上有数据可读
      3. 有数据可读时，epoll_wait 通知主线程，主线程从 socket 中循环读完数据，将数据封装成一个请求对象放入请求队列
      4. 睡眠在请求队列中的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往 epoll 事件表中注册 socket 上的写就绪事件
      5. 主线程调用 epoll_wait 等待 socket 可写
      6. socket 可写时， epoll_wait 通知主线程，主线程往 socket 上写入服务器处理客户请求的结果

---

+  **线程池的优点是什么？**
  + 线程池旨在降低创建和销毁线程的频率，使其维持合理数量的线程，并让空闲的线程重新承担新的任务 。
  + 连接池是指维持连接的缓存池，尽量重用已有的连接，降低创建和关闭连接的频率。
  + 这两种技术能降低系统开销，但当请求数目远远大于池中元素的数目时，没有显著的效果。特别是在阻塞IO下。

+ 项目里实现了哪些HTTP请求呢，处理的时候如何分辨这些请求呢？
+ 设想这样一种场景，我的web服务器里面有一张表格，现在浏览器需要请求这个表格中 id=张三 的内容，同时返回到浏览器也需要以表格的形式展现。

---

## 十三.智力题









---

## 综合面试

+ 智力题 楼层丢鸡蛋
+ 8个赛道，64匹马，要选前4，需要多少轮。
+ 一个检测试剂10分钟检测一位病人，工厂有1000人，最少多少支试剂能10分钟内检测出来哪一位患病？讲出原理（小猪喝水问题的变种
+ 1-100，报号，每次剔除奇数位置的人，问这样剔除以后最后剩下的是几号？64
+ 自我介绍，将自己的经历和项目做一些介绍； 
+ 自己所做邻域的国内外现状、学术界和工业界的状况（因为我研究生期间做的内容比较小众）； 
+ 应聘季自己应聘的优势和劣势； 
+ 对华为的文化怎么理解； 
+ 自己最喜欢的学习方式； 
+ 将来的职业规划；