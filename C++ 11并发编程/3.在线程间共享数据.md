## 一. 线程之间共享数据的问题

当涉及到共享数据时，问题很可能是因为共享数据修改所导致。

+ 如果共享数据是只读的，那么只读操作不会影响到数据，更不会涉及对数据的修改，所以所有线程都会获得同样的数据。
+ 但是，当一个或多个线程要修改共享数据时，就会产生很多麻烦。这种情况下，就必须小心谨慎，才能确保一切所有线程都工作正常。

**不变量** (invariants)是对于特殊结构体的描述；比如，“变量包含列表中的项数”。不变量通常会在一次更新中被破坏，特别是比较复杂的数据结构，或者一次更新就要改动很大的数据结构。

破坏不变量的后果是多样，无论结果如何，都是并行代码常见错误：竞态条件。

### 1.竞态条件

并发中竞争条件的形成，取决于一个以上线程的相对执行顺序，每个线程都抢着完成自己的任务。当不变量遭到破坏时，才会产生条件竞争。并发中对数据的条件竞争通常表示为恶性条件竞争，我们对不产生问题的良性条件竞争不感兴趣。

### 2.解决方法

+ 最简单的办法就是对数据结构采用某种保护机制，确保只有进行修改的线程才能看到不变量被破坏时的中间状态。从其他访问线程的角度来看，修改不是已经完成了，就是还没开始。

+ 对数据结构和不变量的设计进行修改，修改完的结构必须能完成一系列不可分割的变化，也就是保证每个不变量保持稳定的状态，这就是所谓的无锁编程。

  > 这种方式很难得到正确的结果。如果到这个级别，无论是内存模型上的细微差异，还是线程访问数据的能力，都会让工作变的复杂。

+ 使用事务的方式去处理数据结构的更新(如同对数据库进行更新一样)。所需的一些数据和读取都存储在事务日志中，然后将之前的操作合为一步，再进行提交。当数据结构被另一个线程修改后，或处理已经重启的情况下，提交就会无法进行，这称作为“软件事务内存”。

---

## 二.使用互斥量保护共享数据

### 1.C++ 中使用互斥量

C++中通过实例化`std::mutex`创建互斥量，通过调用成员函数lock()进行上锁，unlock()进行解锁。

> 不推荐实践中直接去调用成员函数，记住在每个函数出口都要去调用unlock()，也包括异常的情况，这样过于繁琐，容易忘记解锁操作。

C++标准库为互斥量提供了一个RAII语法的模板类`std::lock_guard`，其会在构造的时候提供已锁的互斥量，并在析构的时候进行解锁，从而保证了一个已锁的互斥量总是会被正确的解锁。

### 2.需要精心组织代码来保护共享数据

 **切勿将受保护数据的指针或引用传递到互斥锁作用域之外，无论是函数返回值，还是存储在外部可见内存，亦或是以参数的形式传递到用户提供的函数中去。**

### 3. 接口内在的条件竞争

stack容器返回一个拷贝而非引用(即遵循了3.2.2节的准则)，对内部数据使用一个互斥量进行保护，不过这个接口仍存在条件竞争。

这个问题不仅存在于基于互斥量实现的接口中，在无锁实现的接口中，条件竞争依旧会产生。这是接口的问题，与其实现方式无关。

```c++
template<typename T,typename Container=std::deque<T> >
class stack
{
public:
  explicit stack(const Container&);
  explicit stack(Container&& = Container());
  template <class Alloc> explicit stack(const Alloc&);
  template <class Alloc> stack(const Container&, const Alloc&);
  template <class Alloc> stack(Container&&, const Alloc&);
  template <class Alloc> stack(stack&&, const Alloc&);

  bool empty() const;
  size_t size() const;
  T& top();
  T const& top() const;
  void push(T const&);
  void push(T&&);
  void pop();
  void swap(stack&&);
};
```

虽然empty()和size()可能在被调用并返回时是正确的，但其的结果是不可靠的；当它们返回后，其他线程就可以自由地访问栈，并且可能push()多个新元素到栈中，也可能pop()一些已在栈中的元素。这样的话，之前从empty()和size()得到的结果就有问题了。

定义线程安全的堆栈：

```c++
#include <exception>
#include <memory>
#include <mutex>
#include <stack>

struct empty_stack: std::exception{
  	const char* what() const throw(){ return "empty stack!";}
};

template<typename T>
class threadsafe_stack{
private:
    std::stack<T> data;
    mutable std::mutex m;
public:
  	threadsafe_stack(): data(std::stack<T>()){}
  
    threadsafe_stack(const threadsafe_stack& other) {
      std::lock_guard<std::mutex> lock(other.m);
      data = other.data; // 1 在构造函数体中的执行拷贝
    }
  
    threadsafe_stack& operator=(const threadsafe_stack&) = delete;
  
    void push(T new_value){
      std::lock_guard<std::mutex> lock(m);
      data.push(new_value);
    }

    std::shared_ptr<T> pop(){
      std::lock_guard<std::mutex> lock(m);
      if(data.empty()) throw empty_stack(); // 在调用pop前，检查栈是否为空
      std::shared_ptr<T> const res(std::make_shared<T>(data.top())); // 在修改堆栈前，分配出返回值
      data.pop();
      return res;
    }

    void pop(T& value){
      std::lock_guard<std::mutex> lock(m);
      if(data.empty()) throw empty_stack();
      value=data.top();
      data.pop();
    }

    bool empty() const {
      std::lock_guard<std::mutex> lock(m);
      return data.empty();
    }
};
```

+ 对top()和pop()函数的讨论中，锁的粒度太小，需要保护的操作并未全覆盖到，从而出现竞态条件。

+ 不过，锁住的颗粒过大同样会有问题。还有一个问题，一个全局互斥量要去保护全部共享数据，会使得并发优势不再。
+ 细粒度锁定方案的一个问题就是有时为了保护操作中的所有数据，需要不止一个互斥元。但是需要多个互斥元时，时，有时会出现另一个潜在的问题将：死锁。

### 4. 死锁的描述与解决

一对线程需要对他们所有的互斥量做一些操作，其中每个线程都有一个互斥量，且等待另一个解锁。这样没有线程能工作，因为他们都在等待对方释放互斥量。这种情况就是死锁，它的最大问题就是由两个或两个以上的互斥量来锁定一个操作。

C++标准库有办法解决这个问题，`std::lock`——可以一次性锁住多个(两个以上)的互斥量，并且没有副作用(死锁风险)。

```c++
// 这里的std::lock()需要包含<mutex>头文件
class some_big_object;
void swap(some_big_object& lhs,some_big_object& rhs);
class X{
private:
    some_big_object some_detail;
    std::mutex m;
public:
    X(some_big_object const& sd):some_detail(sd){}

    friend void swap(X& lhs, X& rhs){
      if(&lhs==&rhs)
          return;
      std::lock(lhs.m,rhs.m); // 1
      std::lock_guard<std::mutex> lock_a(lhs.m,std::adopt_lock); // 2
      std::lock_guard<std::mutex> lock_b(rhs.m,std::adopt_lock); // 3
      swap(lhs.some_detail,rhs.some_detail);
    }
};
```

+ 首先，检查参数是否是不同的实例，因为操作试图获取`std::mutex`对象上的锁，所以当其被获取时，结果很难预料。(一个互斥量可以在同一线程上多次上锁，标准库中`std::recursive_mutex`提供这样的功能。详情见3.3.3节)。

+ 然后，调用`std::lock()`①锁住两个互斥量，并且两个`std:lock_guard`实例已经创建好②③。提供`std::adopt_lock`参数除了表示`std::lock_guard`对象可获取锁之外，还将锁交由`std::lock_guard`对象管理，而不需要`std::lock_guard`对象再去构建新的锁。
+ 这样，就能保证在大多数情况下，函数退出时互斥量能被正确的解锁(保护操作可能会抛出一个异常)，也允许使用一个简单的“return”作为返回。

**避免死锁的进阶指导：**

+ 避免嵌套锁

+ 避免在持有锁时调用用户所提供的代码

+ 使用固定顺序获取锁

+ 使用锁层次结构

  > 对应用进行分层，并且识别在给定层上所有可上锁的互斥量。只有锁层次更高的才能对层次低的再次上锁

### 5.更灵活的锁——std::unique_lock

`std::unqiue_lock`使用更为自由的不变量，这样`std::unique_lock`实例不会总与互斥量的数据类型相关，使用起来要比`std:lock_guard`更加灵活。

+ 可将`std::adopt_lock`作为第二个参数传入构造函数，对互斥量进行管理；
+ 也可以将`std::defer_lock`作为第二个参数传递进去，表明互斥量应保持解锁状态。

交换操作中`std::lock()`和`std::unique_lock`的使用

```c++
class some_big_object;
void swap(some_big_object& lhs,some_big_object& rhs);
class X{
private:
    some_big_object some_detail;
    std::mutex m;
public:
    X(some_big_object const& sd):some_detail(sd){}
    friend void swap(X& lhs, X& rhs){
        if(&lhs==&rhs)
            return;
        std::unique_lock<std::mutex> lock_a(lhs.m,std::defer_lock); // 1 
        std::unique_lock<std::mutex> lock_b(rhs.m,std::defer_lock); // 1 std::def_lock 留下未上锁的互斥量
        std::lock(lock_a,lock_b); // 2 互斥量在这里上锁
        swap(lhs.some_detail,rhs.some_detail);
    }
};
```

### 6.在作用域之间转移锁

`std::unique_lock`实例没有与自身相关的互斥量，一个互斥量的所有权可以通过移动操作，在不同的实例中进行传递。 `std::unique_lock`是可移动，但不可赋值的类型。

```c++
std::unique_lock<std::mutex> get_lock(){
    extern std::mutex some_mutex;
    std::unique_lock<std::mutex> lk(some_mutex);
    prepare_data();
    return lk;  // 1
}
void process_data(){
    std::unique_lock<std::mutex> lk(get_lock());  // 2
    do_something();
}
```

lk在函数中被声明为自动变量，它不需要调用`std::move()`，可以直接返回①(编译器负责调用移动构造函数)。process_data()函数直接转移`std::unique_lock`实例的所有权②，调用do_something()可使用的正确数据(数据没有受到其他线程的修改)。

### 7.锁定在恰当的粒度

锁的粒度是一个 **摆手术语** (hand-waving term)，用来描述通过一个锁保护着的数据量大小。 **一个细粒度锁** (a fine-grained lock)能够保护较小的数据量， **一个粗粒度锁** (a coarse-grained lock)能够保护较多的数据量。选择粒度对于锁来说很重要：

+ 当有线程持有锁的时间过长，这就会增加等待的时间

`std::unique_lock`在这种情况下工作正常，在调用unlock()时，代码不需要再访问共享数据；而后当再次需要对共享数据进行访问时，就可以再调用lock()了。

```c++
void get_and_process_data(){
    std::unique_lock<std::mutex> my_lock(the_mutex);
    some_class data_to_process=get_next_data_chunk();
    my_lock.unlock();  // 1 不要让锁住的互斥量越过process()函数的调用
    result_type result=process(data_to_process);
    my_lock.lock(); // 2 为了写入数据，对互斥量再次上锁
    write_result(data_to_process,result);
}
```

+ 不需要让锁住的互斥量越过对process()函数的调用，所以可以在函数调用①前对互斥量手动解锁，并且在之后对其再次上锁②。

比较操作符中一次锁住一个互斥量：

```c++
class Y{
private:
    int some_detail;
    mutable std::mutex m;
    int get_detail() const{
      	std::lock_guard<std::mutex> lock_a(m);  // 1
      	return some_detail;
    }
public:
    Y(int sd):some_detail(sd){}

    friend bool operator==(Y const& lhs, Y const& rhs){
        if(&lhs==&rhs)
          	return true;
        int const lhs_value=lhs.get_detail();  // 2
        int const rhs_value=rhs.get_detail();  // 3
        return lhs_value==rhs_value;  // 4
    }
};
```

在这个例子中，比较操作符首先通过调用get_detail()成员函数检索要比较的值②③，函数在索引值时被一个锁保护着①。比较操作符会在之后比较索引出来的值④。注意：虽然这样能减少锁持有的时间，一个锁只持有一次(这样能消除死锁的可能性)，这里有一个微妙的语义操作同时对两个锁住的值进行比较。

---

## 三.保护共享数据的代替设施

### 1. 保护共享数据的初始化过程

**延迟初始化** (Lazy initialization)在单线程代码很常见——每一个操作都需要先对源进行检查，为了了解数据是否被初始化，然后在其使用前决定，数据是否需要初始化：

```c++
std::shared_ptr<some_resource> resource_ptr;
void foo(){
    if(!resource_ptr){
        resource_ptr.reset(new some_resource);  // 1
    }
    resource_ptr->do_something();
}
```

当共享数据对于并发访问是安全的，①是转为多线程代码时，需要保护的，但是下面天真的转换会使得线程资源产生不必要的序列化。这是因为每个线程必须等待互斥量，为了确定数据源已经初始化了。

使用一个互斥量的延迟初始化(线程安全)过程

```c++
std::shared_ptr<some_resource> resource_ptr;
std::mutex resource_mutex;

void foo(){
    std::unique_lock<std::mutex> lk(resource_mutex);  // 所有线程在此序列化 
    if(!resource_ptr){
      resource_ptr.reset(new some_resource);  // 只有初始化过程需要保护 
    }
    lk.unlock();
    resource_ptr->do_something();
}
```

C++标准库提供了`std::once_flag`和`std::call_once`来处理这种情况。使用`std::call_once`比显式使用互斥量消耗的资源更少，特别是当初始化完成后。

```c++
std::shared_ptr<some_resource> resource_ptr;
std::once_flag resource_flag;  // 1

void init_resource(){
  	resource_ptr.reset(new some_resource);
}

void foo(){
    std::call_once(resource_flag,init_resource);  // 可以完整的进行一次初始化
    resource_ptr->do_something();
}
```

在这个例子中，`std::once_flag`①和初始化好的数据都是命名空间区域的对象，但是 `std::call_once()` 可仅作为延迟初始化的类型成员。

### 2.保护很少更新的数据结构

对于很少更新的资源，要求线程独占数据结构的访问权，直到其完成更新操作。当更新完成，数据结构对于并发多线程访问又会是安全的。

使用`std::mutex`来保护数据结构，显的有些反应过度(因为在没有发生修改时，它将削减并发读取数据的可能性)。这里需要另一种不同的互斥量，这种互斥量常被称为“读者-作者锁”，因为其允许两种不同的使用方式：

+ 一个“作者”线程独占访问和共享访问
+ 多个“读者”线程并发访问。

使用`boost::shared_mutex`来做同步。

+ 对于更新操作，可以使用`std::lock_guard<boost::shared_mutex>`和`std::unique_lock<boost::shared_mutex>`上锁。作为`std::mutex`的替代方案，与`std::mutex`所做的一样，这就能保证更新线程的独占访问。
+ 因为其他线程不需要去修改数据结构，所以其可以使用`boost::shared_lock<boost::shared_mutex>`获取访问权。这与使用`std::unique_lock`一样，除非多线程要在同时获取同一个`boost::shared_mutex`上有共享锁。
+ 唯一的限制： **当任一线程拥有一个共享锁时，这个线程就会尝试获取一个独占锁，直到其他线程放弃他们的锁；同样的，当任一线程拥有一个独占锁时，其他线程就无法获得共享锁或独占锁，直到第一个线程放弃其拥有的锁。**

```c++
#include <map>
#include <string>
#include <mutex>
#include <boost/thread/shared_mutex.hpp>

class dns_entry;
class dns_cache{
    std::map<std::string,dns_entry> entries;
    mutable boost::shared_mutex entry_mutex;
public:
    dns_entry find_entry(std::string const& domain) const{
        boost::shared_lock<boost::shared_mutex> lk(entry_mutex);  // 1
        std::map<std::string,dns_entry>::const_iterator const it = entries.find(domain);
        return (it==entries.end())?dns_entry():it->second;
    }
    void update_or_add_entry(std::string const& domain,dns_entry const& dns_details){
        std::lock_guard<boost::shared_mutex> lk(entry_mutex);  // 2
        entries[domain]=dns_details;
    }
};
```

+ find_entry()使用`boost::shared_lock<>`来保护共享和只读权限①；这就使得多线程可以同时调用find_entry()，且不会出错。
+ 另一方面，update_or_add_entry()使用`std::lock_guard<>`实例，当表格需要更新时②，为其提供独占访问权限；update_or_add_entry()函数调用时，独占锁会阻止其他线程对数据结构进行修改，并且阻止线程调用find_entry()。

### 3.递归锁

当一个线程已经获取一个`std::mutex`时(已经上锁)，并对其再次上锁，这个操作就是错误的，并且继续尝试这样做的话，就会产生未定义行为。然而，在某些情况下，一个线程尝试获取同一个互斥量多次，而没有对其进行一次释放是可以的。之所以可以，是因为`C++`标准库提供了`std::recursive_mutex`类。其功能与`std::mutex`类似，除了你可以从同一线程的单个实例上获取多个锁。互斥量锁住其他线程前，你必须释放你拥有的所有锁，所以当你调用lock()三次时，你也必须调用unlock()三次。正确使用`std::lock_guard<std::recursive_mutex>`和`std::unique_lock<std::recursive_mutex>`可以帮你处理这些问题。

